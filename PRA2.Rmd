---
title: "Tipologia y Ciclo de vida de los Datos. Practica 2"
author: 'Autores: Alexis Germán Arroyo Peña y Gabriel Pulido de Torres'
date: "Enero 2021"
output:
  pdf_document:
    highlight: zenburn
    toc: yes
    latex_engine: xelatex
    number_sections: yes
    df_print: kable
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: PRA-header.html
  word_document: default
fontfamily: arev
---

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

```{r  message= FALSE, warning=FALSE, include=FALSE}
library(funModeling)
library(mice)
library(car)
library(gmodels)
library(kableExtra)
library(gridExtra)
library(grid)
library(nortest)
library(C50)
library(caret)
library(dplyr)
library(rpart)
library(rpart.plot)
library(tibble)
library(ggplot2)
library(ggpubr)
library(caTools)
library(factoextra)
library(corrplot)
library(knitr)
library(sqldf)
library(readr)
library(scales)
library(pROC)
library(xgboost)
library(randomForest)
library(tidyr)
library(beeswarm)
set.seed(123, sample.kind="default", normal.kind = "default")



```

# Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?

Como objetivo de esta práctica se ha optado por analizar el conjunto de datos del titanic.

Este conjunto de datos incluye información acerca de los pasajeros que iban en el Titanic, en el que murieron 1500 personas en 1912. Disponemos tanto de información descriptiva del tipo de pasajero como un indicador de su supervivencia al hundimiento o no. La pregunta que nos marcamos como objetivo es: ¿las variables aportadas son suficientes para crear un modelo predictivo que prediga la supervivencia de un determinado pasajero?

El conjunto de datos del Titanic permite entrenar modelos predictivos supervisados. Contiene un número manejable de datos y de atributos de distintos tipos.
Además, es un conjunto que no está limpio (por ejemplo, contiene elementos nulos) lo que obligará a poner en práctica técnicas aprendidas de limpieza de datos.

**Estructura del dataset**

A continuación, realizamos un primer contacto con el conjunto de datos, visualizando su estructura.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos el fichero de datos
data <- read.csv('train.csv',stringsAsFactors = FALSE, na.strings = "")
dim.data.frame(data)

# Verificamos la estructura del conjunto de datos
str(data)
```

El conjunto de datos está formado 12 variables y 891 observaciones.

**Descripción del conjunto de datos:**

- Passengerld: 
  Contador de pasajeros del 1 al 891.

- Survived:
  nos indica si el pasajero sobrevivió o no (0= No, 1= Si).

- pClass:
  nos indica la clase a la que pertenece el ticket, 1=1st (clase alta), 2=2nd (clase media) y 3=3rd (clase baja).

- Name:
  nombre completo del pasajero.
  
- Sex:
  sexo del pasajero (Female o Male).
  
- Age:
  edad del pasajero
  
- SibSp:
  número de hermanos/hermanas, hermanastros/hermanastros y marido o esposa del pasajero que también iban a bordo.

- Parch:
  número de hijas, hijos, padre y madre del pasajero a bordo del Titanic.
  
- Ticket: 
  número del ticket del pasajero.

- Fare:
  la tarifa del pasajero en dólares.

- Cabin:
  código identificativo de la cabina.
  
- Embarked:
  el puerto en el que embarcó el pasajero (C = Cherbourg, Q =Queenstown, S = Southampton).


# Integración y selección de los datos de interés a analizar.

El conjunto de datos que se proporciona en Kaggle está dividido en dos partes, un conjunto de datos de train, y un conjunto de datos de test.
La diferencia principal es que mientras que en el conjunto de datos de train disponemos del valor de la variable Survived, en el de test no disponemos de esa variable.

Como parte de los modelos que vamos a diseñar son modelos supervisados, a la hora de validarlos no podemos usar el conjunto de datos de test, por lo que hemos optado trabajar únicamente con los de train sin fusionarlos. 

En el apartado anterior leímos los datos en un dataframe (al que llamamos "data"). Recordamos su dimensionalidad y comprobamos los nombres y tipos de las variables.

```{r warning=FALSE, echo=FALSE}
dim.data.frame(data)
sapply(data, function(x) class(x))
```

Comprobamos si hay registros duplicados usando el comando unique()

```{r warning=FALSE}
data_unique <- unique(data)
dim.data.frame(data_unique)
remove(data_unique)
```

La dimensionalidad ha quedado exactamente igual que cuando cargamos el conjunto de datos. Esto nos hace ver que no existen registros duplicados.

Revisamos la estructura de nuestro dataset:

```{r warning=FALSE}
summary(data)
df_status(data)
```

Podemos visualizar una muestra de los primeros registros de nuestro dataframe:

```{r warning=FALSE}
head(data, 10)
```


Existen variables que carecen de interés por ser identificadoras de cada registro. Estamos haciendo referencia a “PassengerId”, “Ticket” y “Name”. No nos interesa tener unívocamente identificado cada caso para realizar algún tipo de análisis por lo que no aportan nada a nuestro estudio.

## PersonasTicket y Price 

Antes de eliminar la variable **Ticket**, nos va a servir para conocer el precio unitario que han pagado los pasajeros, ya que la variable **Fare** es la tarifa pagada en el ticket, pero dentro del mismo ticket pueden incluirse a varias personas. Inicialmente, vamos a obtener el número de personas que están incluidas en un mismo ticket.

```{r warning=FALSE}
nrow(table(data$Ticket, data$Fare))
length(unique(data$Ticket))

dt <- data %>% group_by(Ticket, Fare) %>% 
  filter(row_number() == 1)

kbl(head(dt, n = 20), booktabs = T) %>% 
  kable_styling(latex_options = c("striped", "scale_down"))

```

Podemos obtener el precio por persona al dividir Fare entre los integrantes del ticket:

```{r warning=FALSE}
ticket_personas <- as.data.frame(data %>% 
                                   group_by(Ticket) %>% 
                                   dplyr::summarize(PersonasTicket=n()))
```

Creamos un nuevo dataframe, "ticket_personas" al que asignamos las variables **Ticket** y **PersonasTicket** 

```{r warning=FALSE}
df_status(ticket_personas)
```

Este dataframe lo combinamos con el dataframe original a través del número de ticket para incorporar el número de personas al dataframe original. Tras lo cual podemos eliminar el dataframe ticket_personas.

```{r warning=FALSE}
data <- merge(data, ticket_personas, by = "Ticket")
remove(ticket_personas)
```

Hemos incluido a nuestros datos la variable nueva “PersonasTicket”, la cual utilizaremos para dividir la tarifa del ticket “Fare” entre “PersonasTicket” para crear la variable “Price”. Esta nueva variable representa el precio por persona que se paga en el billete.

```{r warning=FALSE}
data$Price <- data$Fare / data$PersonasTicket
```

Tras realizar esto, procedemos a eliminar todas las variables que no utilizaremos: PassengerId, Name, Ticket, PersonasTicket:

```{r warning=FALSE}
data <- select(data, -PassengerId, -Name, -Ticket, -PersonasTicket)
```

## FamilySize

Podemos crear una nueva variable, **FamilySize**, que será la suma de **Parch** (número de padres / hijos a bordo) y **SibSp** (sibling: número de hermanos del pasajero, spouse: cónyuge del pasajero), más el propio viajero en cuestión (haciendo esta variable como mínimo igual a 1).

```{r warning=FALSE}
data$FamilySize = data$Parch + data$SibSp + 1
```

## Revisión y conversion de tipos

Debemos convertir las variables **Sex**, **Survived**, **Pclass** y **Embarked** a “factor”. Estas tienen un número finito de valores por lo que, aunque puedan ser numéricas, las discretizamos convirtiendo sus valores en factores.

```{r warning=FALSE}
data$Sex <- as.factor(data$Sex)
data$Survived <- as.factor(data$Survived)
data$Pclass <- as.factor(data$Pclass)
data$Embarked <- as.factor(data$Embarked)
```

Nos quedarían como variables numéricas: **Age**, **SubSp**, **Parch**, **FamilySize**, **Fare** y **Price**

```{r warning=FALSE}
summary(data)
```

\newpage
# Limpieza de los datos.

Ahora nos toca analizar aquellos valores que se presenten nulos y/o vacíos. Mostramos a continuación un resumen del estado de nuestras 8 variables actuales:

```{r warning=FALSE}
df_status(data)
```

\newpage
## Elementos nulos y ceros. 

### Corrección de elementos nulos

Vamos a analizar los elementos nulos que se encuentran en el dataset

En la tabla anterior observamos que el campo **Age** tiene un 19.87% de nulos, **Cabin** más de un 77% y **Embarked** tiene 2 valores nulos.
Analizamos cada uno de ellos con más detalles para decidir las acciones a realizar.

#### Cabin\

Por su número tan elevado de casos, un 77%, y por no ser significativa para nuestros objetivos, se opta por eliminar esta variable.

```{r warning=FALSE}
data <- select(data, -Cabin)
```

#### Embarked\

Esta variable presenta 2 valores nulos. Al ser pocos casos, decidimos imputar el valor que más se repite: Embarked=S (Southampton)

```{r warning=FALSE}
data %>% group_by(Embarked) %>% count(Embarked)
data_Embarked <- sort(table(data$Embarked, useNA = "ifany"), decreasing = TRUE)
```

Gráficamente:

```{r warning=FALSE}
dat_plot <- as.data.frame(data_Embarked)
ggplot(dat_plot, aes(x=Var1, y=Freq, fill=Var1)) +
  geom_bar(stat = "identity", color = "black") +
  geom_text(aes(label=Freq), vjust = -0.4, color="black", size=3) +
  labs(x='Embarked', y='Count') + 
  theme(legend.position = "none")

data$Embarked[is.na(data$Embarked)] <- names(data_Embarked[1])
```

#### Age\

Contiene concretamente 177 registros con valores nulos.

Analizamos la distribución de la variable **Age** teniendo en cuenta sólo los registros donde hay valores.
Para ello creamos un nuevo dataset sin los registros nulos de Age:

```{r warning=FALSE}
data_NoNA <- data[which(!is.na(data$Age)),]
```

Observamos gráficamente como se distribuye la variable Age en este dataset:

```{r warning=FALSE, echo=FALSE}
ggplot(data_NoNA, aes(Age))+
  geom_histogram(aes(y = ..density..), bins=50, fill="steelblue", color="blue") + 
  stat_function(fun = dnorm, args = list(mean = mean(data_NoNA$Age), sd = sd(data_NoNA$Age)))
```

Comprobamos posibles relaciones entre la edad y alguna otra variable. Para ello iremos analizando Age con las distintas variables.

##### Age vs Sex\

Observamos gráficamente la relación entre la edad y el género

```{r warning=FALSE,  echo=FALSE}
titulo <- 'Age vs Sex'
ggplot(data_NoNA, aes(y=Age, x=Sex, fill=Sex)) + geom_boxplot() + labs(title = paste0('Boxplot: ', titulo)) + ylab("Age") + xlab("Sex")
```

No se aprecian diferencias significativas de edad en función del género

##### Age vs Embarked\

Observamos gráficamente la relación entre la edad y el puerto de Embarque

```{r warning=FALSE,  echo=FALSE}
titulo <- 'Age vs Embarked'
ggplot(data_NoNA, aes(y=Age, x=Embarked, fill=Embarked)) + 
  geom_boxplot() + labs(title = paste0('Boxplot: ', titulo)) + ylab("Age") + xlab("Embarked")
```

No se aprecian diferencias significativas con respecto a las medias de edad en cada una de las clases de **Embarked**.

##### Age vs Pclass\

Observamos gráficamente la relación entre Age y Pclass:

```{r warning=FALSE,  echo=FALSE}
titulo <- 'Age vs Pclass'
ggplot(data_NoNA, aes(y=Age, x=Pclass, fill=Pclass)) + 
  geom_boxplot() + labs(title = paste0('Boxplot: ', titulo)) + ylab("Age") + xlab("Pclass")
```

Observamos una relación entre la edad y la clase en que viajaban los pasajeros: Los pasajeros de clase 1 (alta) tenían generalmente mayor edad que los de clase 2 (media) e igualmente sucede con los de clase 3 (baja). Lo cual es lógico (más edad más poder adquisitivo).

##### Age vs Variables numéricas\

Vemos las distintas correlaciones de las variables numéricas

```{r warning=FALSE,  echo=FALSE}
lista<-sapply(data, is.numeric) 
data_num_NoNA = data_NoNA[,lista]
```


```{r warning=FALSE,  echo=FALSE}
corrplot.mixed(cor(data_num_NoNA))
```

Observamos una correlación negativa con **SibSp** y con **Parch**.

##### Imputación de valores a Age\

Vamos a realizar dos simulaciones diferentes de imputación y nos quedaremos con la mejor:

**Caso 1: Imputar la media de Age a todos los elementos faltantes**

```{r warning=FALSE}
data$Age1 <- data$Age
data$Age1[is.na(data$Age1)] <- mean(data_NoNA$Age)

ggplot(data, aes(Age1)) +
  geom_histogram(aes(y = ..density..), bins=50, fill="steelblue", color="blue") + 
  stat_function(fun = dnorm, args = list(mean = mean(data$Age1), sd = sd(data$Age1)))
```

**Caso 2: Imputando datos de **Age**, con MICE (Multivariate Imputation via Chained Equations)**

En este caso se predicen los valores de **Age**, con el resto de valores observados (**Pclass**, **SibSp**, **Parch**, **Sex** y **Age**).

```{r warning=FALSE}
columnas <- c('Pclass', 'SibSp', 'Parch', 'Sex', 'Age')

mice_imputar <- mice(data = data[, columnas], method = "rf")
mice_completo <- mice::complete(mice_imputar)
data$Age2 <- data$Age
data$Age2[is.na(data$Age2)]<- mice_completo$Age[is.na(data$Age2)]
```

Observamos la gráfica:

```{r warning=FALSE,  echo=FALSE}
ggplot(data, aes(Age2)) +
  geom_histogram(aes(y = ..density..), bins=50, fill="steelblue", color="blue") + 
  stat_function(fun = dnorm, args = list(mean = mean(data$Age2), sd = sd(data$Age2)))
```

Mostramos el resultado de las opciones de imputación más la original:

```{r warning=FALSE}
summary(data$Age)
summary(data$Age1)
summary(data$Age2)
```

Tras ver los resultados nos decantamos por la segunda opción (Age2), ya que la distribución se parece mucho más a la original.
Asignamos y limpiamos el conjunto de datos:

```{r warning=FALSE}
data$Age <- data$Age2
data <- select(data, -Age1, -Age2)
```

### Valores igual a cero\

Recordamos los valores con ceros del dataset

```{r warning=FALSE,  echo=FALSE}
df_status(data)
```

Tenemos un alto número de valores cero tanto en **SibSp** como en **Parch**. No obstante, son valores válidos dentro del rango para estas variables ya que expresan el número de acompañantes del pasajero. 
Sorprende que hay algunos valores cero en **Fare**, aunque pudiera significar que esos tickets fueron gratis debido a algún sorteo o regalo.

### Conclusión limpieza nulos y ceros\

Observamos que hemos eliminado los valores nulos y tenemos un nuevo valor de media y mediana para **Age**.

```{r warning=FALSE}
summary(data)
```

Observamos también los datos tras eliminar variables y tras imputar valores en aquellas variables que presentaban valores nulos. 

```{r warning=FALSE}
df_status(data)
```

## Identificación y tratamiento de valores extremos.

Se considera un valor extremo, outlier, a un valor fuera de rango. Son valores que se salen de la escala esperada visualizando el resto de las observaciones. En la actualidad, el criterio más habitual es considerar un valor extremo a aquel que se encuentra alejado de la media unas tres veces la desviación típica.

**Gráfico boxplot variables numéricas**
 
```{r warning=FALSE}
lista<-sapply(data, is.numeric) 
data_num<-data[,lista] 
boxplot(data_num,las=2)
var.continuas <- vector()
```

De todas las variables numéricas sólamente tres son contínuas: **Age**, **Price** y **Fare**

Analicemos esas tres variables por separado

### Fare\

El boxplot parece indicar que Fare tiene valores extremos. Los identificamos usando el criterio de tres veces la desviación típica:

```{r warning=FALSE}
data_out <- as.data.frame(data$Fare)
data_out$outlier <- FALSE
for (i in 1:ncol(data_out) - 1){
  columna = data_out[, i]
  if (is.numeric(columna)) {
    media = mean(columna)
    desviacion = sd(columna)
    data_out$outlier = (columna> (media+3*desviacion) | columna<(media-3*desviacion))
  }
}
table(data_out$outlier)
```

Con este criterio tenemos identificados 20 posibles *outliers*. 

```{r warning=FALSE}
boxplot.stats(data$Fare)$out
```

Los valores están bien distribuidos, los más altos en las clases altas. Por todo esto, decidimos no realizar ninguna acción con estos *outliers* ya que incluso pueden estar aportando información importante:

**Gráfico outlier Fare**

```{r warning=FALSE}
boxplot(data$Fare~data$Pclass,xlab="Pclass",ylab="Fare",
        col=c("blue","yellow","red"))
```

### Price\

Hacemos un análisis similar con la variable Price:

```{r warning=FALSE}
data_out <- as.data.frame(data$Price)
data_out$outlier <- FALSE
for (i in 1:ncol(data_out) - 1){
  columna = data_out[, i]
  if (is.numeric(columna)) {
    media = mean(columna)
    desviacion = sd(columna)
    data_out$outlier = (columna> (media+3*desviacion) | columna<(media-3*desviacion))
  }
}
table(data_out$outlier)
```

Con boxplot.stats analizamos los outliers, el valor máximo 221:

```{r warning=FALSE}
boxplot.stats(data$Price)$out
```

Los valores más altos están presentes en las clases altas:

**Gráfico boxplot Price**

```{r warning=FALSE}
boxplot(data$Price~data$Pclass,xlab="Pclass",ylab="Price",col=c("blue","yellow","red"))
```

Optamos por considerarlos válidos y no realizamos ninguna accion.

### Age\

Hacemos un análisis similar con la variable Age:

```{r warning=FALSE}
data_out <- as.data.frame(data$Age)
data_out$outlier <- FALSE
for (i in 1:ncol(data_out) - 1){
  columna = data_out[, i]
  if (is.numeric(columna)) {
    media = mean(columna)
    desviacion = sd(columna)
    data_out$outlier = (columna> (media+3*desviacion) | columna<(media-3*desviacion))
  }
}
table(data_out$outlier)
```

Con boxplot.stats:

```{r warning=FALSE}
boxplot.stats(data$Age)$out
```

Podríamos tener 2 valores outliers pero observando los valores devueltos por boxplot.stats no los vamos a considerar significativos.

\newpage
# Análisis de los datos.

## Planificación de los análisis a aplicar.

Nos interesa poder realizar diferentes tipos de análisis en función de diferentes subconjuntos de datos, como puede ser el género, la clase en la que viajan los pasajeros, el puerto en el que han embarcado, grupos por edad, índice de supervivencia de los niños respecto a los adultos, etc.

### Niños\

Definimos una variable Child para aquellos registros en los que la edad sea inferior a 8 años.

```{r warning=FALSE}
edad_corte = 8
data$Child[data$Age <= edad_corte] <- 1
data$Child[data$Age > edad_corte] <- 0
data$Child <- as.factor((data$Child))
```

### Género\

Agrupamos por el género, creando una variable para cada uno de los géneros

```{r warning=FALSE}
Mujeres <- data[which(data$Sex == 'female'),]
Hombres <- data[which(data$Sex == 'male'),]
```

### Lugar de embarque\

Agrupamos por el lugar de embarque creando una variable por cada uno de los lugares

```{r warning=FALSE}
EmbarqueC <- data[which(data$Embarked == 'C'),]
EmbarqueQ <- data[which(data$Embarked == 'Q'),]
EmbarqueS <- data[which(data$Embarked == 'S'),]

```

### Clase\

Agrupamos por clase

```{r warning=FALSE}
FirstClass <- data[which(data$Pclass == 1),]
SecondClass <- data[which(data$Pclass == 2),]
ThirdClass <- data[which(data$Pclass == 3),]
```

### Edades\

Vamos a discretizar los valores por grupos de edades, añadiendo una columna al dataset (AgeInterval)

```{r warning=FALSE,  echo=FALSE}
data["AgeInterval"] <- cut(data$Age, breaks = c(0,13,18,40,55, 100), labels = c("0-12", "13-17", "18-39","40-54", "55-100"))
data$AgeInterval <- as.factor(data$AgeInterval)
table(data$AgeInterval)
plot(data$AgeInterval)
```

## Comprobación de la normalidad y homogeneidad de la varianza.

### Normalidad\

Algunos test estadísticos requieren que las variables que van a ser analizadas sigan una distribución normal, por tanto tenemos que conocer cuáles son las distribuciones de nuestras variables continuas.
Estas son las variables **Age** y **Fare**. Además, hemos generado una nueva variable a partir de **Fare**, **Price**, y que, por tanto también es una variable cualitativa continua. 

En general, la prueba de *Shapiro-Wilk* se considera una prueba muy potente para contrastar la normalidad de distribuciones. Se asume como hipótesis nula que la población sigue una distribución normal. Si el p-valor obtenido es inferior al nivel de significancia (normalmente α = 0,05) entonces se rechaza la hipótesis nula (y por tanto se concluye que los datos no vienen de una distribución normal). En cambio, si el p-valor es superior al nivel de significancia, entonces no se puede rechazar la hipótesis nula y se asume que los datos siguen una distribución normal.
Además, vamos a aplicar otros dos métodos, la prueba de *Anderson-Darling* y la prueba de *Kolmogorov-Smirnov* (conocida también como K-S)

Creamos un data frame para resumir los tests:

```{r warning=FALSE}
tabla.normalidad <- data.frame('variable' = character(),
                               'Test de Normalidad' = character(),
                               'Valor Estadístico' = numeric(),
                               'p-value' = numeric(),
                               stringsAsFactors = FALSE) 
str(tabla.normalidad)
```

Ahora recorremos todas las variables continuas aplicando los tres tests y añadiéndolos al dataframe:

```{r warning=FALSE}
var.continuas <-c("Age", "Fare", "Price")

for (i in 1:length(var.continuas)){
  variable = var.continuas[i]
  #Test Shapiro-wil
  test = shapiro.test(data[,variable])
  tabla.normalidad[nrow(tabla.normalidad)+1,] = c(variable, test$method, 
                                                  test$statistic, test$p.value)
  
  #Test Anderson-Darling
  test = ad.test(data[,variable])
  tabla.normalidad[nrow(tabla.normalidad)+1,] = c(variable, test$method, 
                                                  test$statistic, test$p.value)
  
  #Test Kolmogorov-Smirnov
  test = ks.test(data[,variable], "pnorm", mean=mean(data[,variable]), 
                 sd=sd(data[,variable]))
  tabla.normalidad[nrow(tabla.normalidad)+1,] = c(variable, test$method, 
                                                  test$statistic, test$p.value)
}

knitr::kable(tabla.normalidad)
```

En todos los casos el *p-value* ha sido inferior a 0.05 y, por lo tanto, se rechaza la hipótesis nula que implicaba que la variable sigue una distribución normal. Ninguna de las 3 variables sigue una distribución normal.

Revisamos gráficamente la distribución de cada una de las variables usando su histograma, curva de densidad y gráficas Q-Q

```{r warning=FALSE, message = FALSE,  echo=FALSE}
for (i in 1:length(var.continuas)) {
  variable=var.continuas[i]
  #Histograma
  print(ggplot(data, aes(data[,variable])) + 
          geom_histogram(aes(y = ..density..), bins=50, fill="steelblue", color="blue") + xlab(variable) +
          stat_function(fun = dnorm, args = list(mean = mean(data[,variable]), sd = sd(data[,variable]))))
  
  #Gráfica Q-Q
  qqnorm(data[,variable], main=paste0('Normal Q-Q Plot ', '(Variable "', variable,'")'))
  qqline(data[,variable], col=2)
  
  print(variable)
}
```

Observamos que la variable **Age** está próxima a una distribución normal por lo cual podemos utilizar el test de *Levene* para la comprobación de varianzas.
Cuando comparamos varianzas lo que estamos comprobando es que las varianzas entre los grupos a comparar son iguales. La hipótesis nula asume la igualdad de varianzas en los diferentes grupos de datos, con lo que si el p-value obtenido es inferior al nivel de significancia (generalmente alpha = 0,05) se rechaza la hipótesis nula y se concluye que hay heterocedasticidad.


#### Age

##### Age con Survived\

Primero, comprobamos la homogeneidad de varianzas de la edad en los grupos de supervivientes y no supervivientes.

```{r warning=FALSE}
leveneTest(data = data, Age ~ Survived, center = mean)
```
En este caso el p-value es superior a 0.05 y por tanto asumimos que hay **homogeneidad de varianzas** entre los grupos

##### Age con Embarked\

Comprobamos el comportamiento de la varianza cuando se trata de la variable edad **Age** con **Embarked**.

```{r warning=FALSE}
leveneTest(data = data, Age ~ Embarked, center = mean)
```

Hay **homogeneidad de varianzas** de **Age** en los grupos que define la variable **Embarked**

##### Age con Pclass\

Comprobamos el comportamiento de la varianza cuando se trata de la variable edad **Age** con **Pclass**.

```{r warning=FALSE}
leveneTest(data = data, Age ~ Pclass, center = mean)
```

Hay **heterogeneidad de varianzas** entre las muestras de **Age**  cuando se agrupan por **Pclass**

##### Age con Sex\

Comprobamos el comportamiento de la varianza cuando se trata de la variable edad **Age** con respecto a **Sex**.

```{r warning=FALSE}
leveneTest(data = data, Age ~ Sex, center = mean)
```

Hay **homogeneidad de varianzas** para *Age* cuando está agrupado por *Sex*

##### Resumen Age\

Resumimos en una tabla los resultados de homogeneidad de la varianza de Age con respecto a los distintos atributos:

| Age con respecto a |  resultado     |
| ------------------ | -------------- |
| Survived           | homogeneidad   |
| Embarked           | homogeneidad   |
| Pclass             | heterogeneidad |
| Sex                | homogeneidad   |


## Aplicación de pruebas estadísticas para comparar los grupos de datos. 

### Análisis de relaciones entre variables

Vamos a analizar las relaciones entre variables para aclarar la dependencia entre ellas y como pueden afectar a las posibilidades de supervivencia:

#### Age y Sex\

Nos gustaría analizar las diferencias entre la media de edad de mujeres y de hombres, utilizando el test paramétrico *t-test de Student*, que requiere que las muestras a comparar sigan una distribución normal.
Comprobemos primero que la variable **Age** sigue una distribución normal:

```{r warning=FALSE}
var.test(Mujeres$Age, Hombres$Age)
```

El resultado nos indica que las varianzas de edad en los grupos de mujeres y hombres son iguales.

Comparamos ahora las medias de los 2 grupos, utilizando *t-Test* indicando que las varianzas de los grupos son iguales. La hipótesis nula será que no hay diferencias significativas entre la media de edades para hombres y mujeres. 

```{r warning=FALSE}
t.test(Mujeres$Age, Hombres$Age, var.equal = TRUE)
```

El valor de p-values es inferior a 0.05, por lo que rechazamos la hipótesis nula. Es decir, **la media de edad por género tiene una diferencia significativa**.

Queremos comprobar ahora si la media de edad de las mujeres es menor que la de los hombres. Por lo tanto, la hipótesis nula corresponde a que la edad de las mujeres es mayor o igual a la de los hombres:

```{r warning=FALSE}
t.test(Mujeres$Age, Hombres$Age, alternative = "less", var.equal = TRUE)
```

Con un p-value menor de 0.5 rechazamos la hipótesis nula, es decir, podemos afirmar que la media de edad de las mujeres es inferior a la media de edad de los hombres.

#### Survival y Sex\

Mostramos gráficamente la relación entre las dos variables:

```{r warning=FALSE, echo=FALSE}
ggplot(data,aes(x=Sex,fill=Survived))+geom_bar()
```

Parece indicar que ser mujer implicaba mas posibilidades de supervivencia que ser hombre. Vamos a confirmar esto realizando algunos contrastes de hipótesis.

Primero, vamos a comprobar la relación entre la supervivencia y el género, analizando si dependiendo de si se era mujer u hombre las posibilidades de supervivencia cambiaban significativamente.
Para hacerlo aplicamos el *test exacto de Fisher* que analiza tablas de contingencia. En este caso la hipótesis nula es que la proporción de mujeres que mueren coincide con la proporción de hombre que mueren en el accidente del Titanic.

```{r warning=FALSE}
fisher.test(table(data$Sex, data$Survived))
```

Con un p-valor < 0.05 rechazamos la hipótesis nula, es decir: **hay diferente proporción de supervivencia entre hombres y mujeres.**

Una vez confirmado que el género si que importaba, vamos a ver quien tiene más probabilidades de supervivencia, si las mujeres o los hombres. La hipótesis nula sería que la proporción de mujeres que mueren es mayor que la de los hombres.

```{r warning=FALSE}
fisher.test(table(data$Sex, data$Survived), alternative = 'less')
```

El valor de p-value inferior a 0.05) con lo que se cumple la hipótesis alternativa: **la proporción de mujeres que mueren es inferior a la de los hombres**.

#### Survival y Pclass\ 

Mostramos gráficamente la relación entre las dos variables:

```{r warning=FALSE,  echo=FALSE}
ggplot(data,aes(x=Pclass,fill=Survived))+geom_bar()
```

El porcentaje de supervivencia por clases disminuye desde la primera hasta la tercera clase, las clases con mas superviencia eran las mejores. Para comprobarlo utilizamos el test *Chi-Cuadrado* (son variables categóricas). Aquí la hipótesis nula nos dice que las variables son independientes. 

```{r warning=FALSE}
test_chisq <- chisq.test(data$Pclass, data$Survived)
test_chisq
```

El valor de p-value es inferior a 0.05, es decir, rechazamos la hipótesis nula, y por tanto afirmamos que las variables no son independientes. Esto quiere decir que **el grado de supervivencia era distinto dependiendo de la clase en la que estuvieses**. 


#### Survived y Embarked\

Mostramos gráficamente la relación entre las dos variables:

```{r warning=FALSE,  echo=FALSE}
ggplot(data,aes(x=Embarked,fill=Survived))+geom_bar()
```

Parece indicar que los embarcados en Southampton tenían menos posibilidades de sobrevivir (tal vez por el número de clase al que accedían). 
Utilizamos *Chi-Squared* para analizar la relación entre las variables **Embarked** y **Survived**.

```{r warning=FALSE}
test_chisq <- chisq.test(data$Embarked, data$Survived)
test_chisq
```

Se rechaza la hipótesis nula, por lo tanto **las variables son dependientes**.

#### Survived y Child\

Mostramos gráficamente la relación entre las dos variables, siendo **Child** una variable que corresponde a los niños de edad igual o inferior a 8 años:

```{r warning=FALSE,  echo=FALSE}
ggplot(data,aes(x=Child,fill=Survived))+geom_bar(position ='fill')
```
Parece que hay más esperanza de supervivencia en ese caso. Aplicamos el *test de Fisher* para comprobar si tienen las mismas probabilidades de supervivencia que el resto de pasajeros. 

```{r warning=FALSE}
fisher.test(table(data$Child, data$Survived))
```

Se rechaza la hipótesis nula, es decir que **las proporciones no coinciden**. 
Analizamos ahora si las probabilidades de supervivencia son mayores o menores. Para ello analizamos si la proporción de no-niños que no sobreviven es menor a la proporción de niños que no sobreviven:

```{r warning=FALSE}
fisher.test(table(data$Child, data$Survived), alternative = 'greater')
```
Se rechaza la hipótesis nula, y se acepta la alternativa, es decir que la **probabilidad de muerte de los no-niños es mayor que la de los niños**.

#### Survived y Age\

Comprobamos ahora si la media de edad de las personas que murieron es similar con la media de edad que sobrevivieron, aplicando el test *t-Test*.

```{r warning=FALSE}
t.test(data$Age[which(data$Survived==0)], data$Age[which(data$Survived == 1)])
```

Se observa que el p-valor es inferior a 0.05, con lo que rechazamos la hipótesis nula (que las medias de edad son coincidentes para fallecidos y supervivientes), pero como ya sabíamos, la distribución de **Age** no sigue exactamente una normal, por lo que vamos a aplicar el *test no paramétrico U de Mann-Whitney*

```{r warning=FALSE}
wilcox.test(x = data$Age[which(data$Survived==0)],
            y = data$Age[which(data$Survived==1)],
            paired =FALSE
            )
```

La prueba no-paramétrica nos devuelve un p-value por encima de 0.05 y por tanto no rechazamos la hipótesis nula, con lo que podemos decir que **la media de edad es similar entre los muertos y los supervivientes del Titanic**.

Gráficamente podemos comprobarlo mediante un Boxplot

```{r warning=FALSE,  echo=FALSE}
colores_defecto_ggplot = (hue_pal()(2))
ggplot(data, aes(x=Survived, y=Age)) +
  scale_x_discrete(name = "Survived", labels = c("0"="no", "1"="Yes")) +
  geom_boxplot() +  
  geom_boxplot(color="black", fill = c(colores_defecto_ggplot[1], colores_defecto_ggplot[2])) +
  ggtitle("Boxplot Survived (by Age")
```

Se puede apreciar que las distribuciones son muy parecidas.


### Modelos

Vamos a aplicar diversos modelos predictivos con respecto a la variable **Survived**. Vamos a utilizar como variables explicativas las variables que traía por defecto el conjunto de datos original, menos las que hemos eliminado durante el proceso de transformación y limpieza de datos.

Creamos un conjunto de entrenamiento y un conjunto de test. Es decir,vamos a crear una partición, un 75% de datos para el entrenamiento, y el 25% restante para validar los modelos.

```{r warning=FALSE}

index_train <- createDataPartition(data$Survived, p=.75, list = FALSE)
data_train <-data[index_train,]
data_test <- data[-index_train, ]

```

Creamos una función que nos imprima correctamente las matrices de confusión a partir de un CrossTable.

```{r warning=FALSE}
# Función necesaria para imprimir la matriz de confusión a partir de un CrossTable
plot_matriz_confusion <- function(par_crosstable) {
  #Obtenemos la matriz de confusion en porcentaje
  datplotconfusion <- as.data.frame(par_crosstable[2]$prop.row)
  colnames(datplotconfusion) <- c('Observacion','Prediccion','Valor')
  datplotconfusion$Valor <- datplotconfusion$Valor*100
  #Ordenamos los factores de las clases
  datplotconfusion <- datplotconfusion %>% arrange(Observacion)
  clasesord <- sort(as.character(levels(datplotconfusion$Observacion)),decreasing = FALSE)
  datplotconfusion$Observacion <- factor(datplotconfusion$Observacion, levels = clasesord)
  #Ordenar las clases descendente (para el plot)
  clasesinv<-rev(as.character(unique(datplotconfusion$Observacion)))
  
  plot1 <- ggplot() +
    geom_tile(aes(x=Observacion, y=Prediccion,fill=Valor), 
              data=datplotconfusion, color="black",size=0.1) +
    labs(x="Observación real (%)",y="Predicción (%)") +
    scale_y_discrete(limits=clasesinv)
  
  plot1 = plot1 + 
    geom_text(aes(x=Observacion, y=Prediccion, label=sprintf("%.2f", Valor)), 
              data=datplotconfusion, size=3, colour="black") +
    scale_fill_gradient(low="gray",high="red")
  
  #Obtenemos la matriz de confusion en numero de muestras
  datplotconfusion <- as.data.frame(par_crosstable[1]$t)
  colnames(datplotconfusion) <- c('Observacion','Prediccion','Valor')
  #Ordenamos los factores de las clases
  datplotconfusion <- datplotconfusion %>% arrange(Observacion)
  clasesord <- sort(as.character(levels(datplotconfusion$Observacion)),decreasing = FALSE)
  datplotconfusion$Observacion <- factor(datplotconfusion$Observacion, levels = clasesord)
  #Ordenar las clases descendente (para el plot)
  clasesinv<-rev(as.character(unique(datplotconfusion$Observacion)))
  plot2 <- ggplot() +
    geom_tile(aes(x=Observacion, y=Prediccion,fill=Valor), 
              data=datplotconfusion, color="black",size=0.1) +
    labs(x="Observación real (nº)",y="Predicción (nº)") +
    scale_y_discrete(limits=clasesinv)
  
  plot2 = plot2 + 
    geom_text(aes(x=Observacion, y=Prediccion, label=sprintf("%d", Valor)), 
              data=datplotconfusion, size=3, colour="black") +
    scale_fill_gradient(low="gray",high="red")
  return(grid.arrange(plot1, plot2, ncol=2))
}
```

Creamos un dataframe en donde iremos guardando los distintos valores de precisión y errores de clasificación.

```{r}
tabla.modelos <- data.frame('Modelo' = character(),
                               'Precisión' = numeric(),
                               'Errores' = numeric(),
                               stringsAsFactors = FALSE) 

str(tabla.modelos)
```

#### Modelo de regresión logística\

Un modelo de regresión logística es un tipo de análisis de regresión que se utiliza para predecir el resultado de una variable categórica, en función de las variables independientes. Nuestra variable objetivo es **Survived**, que toma los valores de 0 o 1 (1 cuando el pasajero sobrevivió al accidente y 0 en caso contrario). 

##### Primer modelo glm\


Creamos un primer modelo glm1 con las variables "original": **Pclass**, **SibSp**, **Parch**, **Sex**, **Age**, **Fare** y **Embarked**

```{r warning=FALSE}
modelo_glm1 <- glm(formula=Survived~ Pclass+SibSp+Parch+Sex+Age+Fare+Embarked, data = data_train, family = binomial(link = "logit"))
summary(modelo_glm1)
```

Se puede observar que tanto las variables **Fare** como **Parch** no aportan nada a la hora de predecir la variable **Survived**.
En el caso de la variable Sex, al tener 2 valores se ha creado la variable **Sexmale**, es decir la parte correspondiente a hombres, mientras que 
la parte de mujeres forma parte del Intercept del modelo. Concretamente vemos que **Sexmale** es una variable significativa, pero con valor negativo (junto con **Pclass3**). Eso significa que esas variables contribuyen negativamente de cara a la supervivencia.

Ahora usamos el conjunto de datos de test para validar nuestro modelo.
(Para este primer modelo mostramos el código como ejemplo)

```{r warning=FALSE}
predict_glm1 <- predict(object=modelo_glm1, newdata=data_test, type = "response")
r1 <- pROC::roc(response=data_test$Survived, predictor = predict_glm1)
threshold_r1 <- pROC::coords(r1, "best", ret = "threshold", transpose="FALSE")
predict_glm1 <- if_else(predict_glm1 < threshold_r1[1,1], 0, 1)
mat.confusion_glm1 <- table(data_test$Survived, predict_glm1)
mat.confusion_glm1
pct.correcto_glm1 <- 100 * sum(diag(mat.confusion_glm1)) / sum(mat.confusion_glm1)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",
              pct.correcto_glm1))

csstab_glm1 <- CrossTable(data_test$Survived, predict_glm1,
                          prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE, 
                          dnn = c('Reality', 'Prediction'))

plot_matriz_confusion(csstab_glm1)
tabla.modelos[nrow(tabla.modelos)+1,] = c("glm1", pct.correcto_glm1, sum(mat.confusion_glm1)-sum(diag(mat.confusion_glm1)))

```

##### Segundo modelo glm\


Construimos un segundo modelo (glm2), similar al anterior pero esta vez partiendo de los resultados del modelo anterior, le vamos a quitar aquellas variables que vimos que no eran significativas para el modelo de predicción. Por lo tanto, tendremos un modelo2 cuyas variables a utilizar serán **Pclass**, **SibSp**, **Sex** y **Age**.

```{r warning=FALSE}
modelo_glm2 <- glm(formula=Survived~ Pclass+SibSp+Sex+Age, data = data_train, family = binomial(link = "logit"))
summary(modelo_glm2)
```

Se comprueba que todas las variables utilizadas son variables significativas para el modelo. Además, el modelo parece haber mejorado un poco en cuanto a la predicción:

```{r warning=FALSE, echo=FALSE}
predict_glm2 <- predict.glm(object=modelo_glm2, newdata=data_test, type = "response")
r2 = pROC::roc(response=data_test$Survived, predictor = predict_glm2)
threshold_r2 <- coords(r2, "best", ret = "threshold")
predict_glm2 <- ifelse(predict_glm2 < threshold_r2[1,1], 0, 1)
mat.confusion_glm2 <- table(data_test$Survived, predict_glm2)
mat.confusion_glm2
pct.correcto_glm2 <- 100 * sum(diag(mat.confusion_glm2)) / sum(mat.confusion_glm2)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",
              pct.correcto_glm2))
csstab_glm2 <- CrossTable(data_test$Survived, predict_glm2,
                          prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE, 
                          dnn = c('Reality', 'Prediction'))

plot_matriz_confusion(csstab_glm2)
tabla.modelos[nrow(tabla.modelos)+1,] = c("glm2", pct.correcto_glm2, sum(mat.confusion_glm2)-sum(diag(mat.confusion_glm2)))
```

##### Tercer modelo glm\


Construimos un tercer modelo (glm3), pero esta vez vamos a intentar utilizar alguna de las variables que hemos construido para ayudar a predecir la supervivencia. Para este caso vamos a utilizar las variables nuevas **Child** y también **FamilySize**. Además, vamos a utilizar tres variables originales: **Pclass**, **Sex** y **Age**.

```{r warning=FALSE}
modelo_glm3 <- glm(formula=Survived~ Sex+Pclass+Age+Child+FamilySize,, data = data_train, family = binomial(link = "logit"))
summary(modelo_glm3)
```

Al igual que pasaba en el modelo2, todas las variables utilizadas han resultado significativas, y además el AIC del modelo ha mejorado ligeramente. Además la capacidad predictiva del modelo ha aumentado un poco:

```{r warning=FALSE, echo=FALSE}
predict_glm3 <- predict.glm(object=modelo_glm3, newdata=data_test, type = "response")
r3 = pROC::roc(response=data_test$Survived, predictor = predict_glm3)
threshold_r3 <- coords(r3, "best", ret = "threshold")
predict_glm3 <- ifelse(predict_glm3 < threshold_r3[1,1], 0, 1)
mat.confusion_glm3 <- table(data_test$Survived, predict_glm3)
mat.confusion_glm3
pct.correcto_glm3 <- 100 * sum(diag(mat.confusion_glm3)) / sum(mat.confusion_glm3)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",
              pct.correcto_glm3))

csstab_glm3 <- CrossTable(data_test$Survived, predict_glm3,
                          prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE, 
                          dnn = c('Reality', 'Prediction'))

plot_matriz_confusion(csstab_glm3)
tabla.modelos[nrow(tabla.modelos)+1,] = c("glm3", pct.correcto_glm3, sum(mat.confusion_glm3)-sum(diag(mat.confusion_glm3)))
```

##### Resumen modelos regresion\

Los diferentes modelos se han comportado de la siguiente forma:

```{r}
knitr::kable(tabla.modelos)
```

#### Árboles de decisión\

Los árboles de decisión son modelos muy sencillos de construir. Utilizaremos los "Recursive Partitioning and Regression Tree" que proporciona la libreria ```rpart```

##### Primer árbol de decisión\

Creamos un primer árbol con los parámetros básicos

```{r warning=FALSE}

tctrl <- caret::trainControl(method = "repeatedcv",
                             number=10, repeats = 3)
model_tree1 <- caret::train(Survived~Sex+FamilySize+Child+Age+Pclass, 
                            data=data_train, 
                            method="rpart",
                            trControl = tctrl)
summary(model_tree1)
```

Dibujamos el árbol

```{r warning=FALSE}
rpart.plot(model_tree1$finalModel)
```

Realizamos la predicción con el modelo construido con rpart y el dataset test

```{r warning=FALSE, echo=FALSE}

predict_tree1 <-predict(model_tree1, data_test)

mat.confusion_tree1 <- table(data_test$Survived, predict_tree1)
mat.confusion_tree1

pct.correcto_tree1 <- 100 * sum(diag(mat.confusion_tree1)) / sum(mat.confusion_tree1)

print(sprintf("El %% de registros correctamente clasificados es: %.4f %%", pct.correcto_tree1))

csstab_tree1 <- CrossTable(data_test$Survived, predict_tree1,
                           prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE, 
                           dnn = c('Reality', 'Prediction'))

plot_matriz_confusion(csstab_tree1)
tabla.modelos[nrow(tabla.modelos)+1,] = c("Decision Tree 1", pct.correcto_tree1, sum(mat.confusion_tree1)-sum(diag(mat.confusion_tree1)))
```

##### Segundo árbol de decisión\

Manteniendo las mismas variables predictivas, pero cambiando la profundidad máxima del árbol (maxdepth) se pueden mejorar los resultados obtenidos:

```{r warning=FALSE}
tctrl <- caret::trainControl(method = "repeatedcv",
                             number=10, repeats = 3)
tgrid <- data.frame(maxdepth = seq(2,10,1))

model_tree2<- train(Survived ~ Sex+FamilySize+Child+Age+Pclass, 
                    data=data_train,
                    trControl=tctrl, 
                    tuneGrid=tgrid,
                    method="rpart2")
```

```{r message= FALSE, warning=FALSE, echo=FALSE}
rpart.plot(model_tree2$finalModel)
```


```{r, message= FALSE, warning=FALSE, echo=FALSE}
summary(model_tree2)
```

Realizamos la predicción con el modelo construido con rpart y el dataset test:

```{r warning=FALSE, echo=FALSE}
predict_tree2 <-predict(model_tree2, data_test)
mat.confusion_tree2 <- table(data_test$Survived, predict_tree2)
mat.confusion_tree2
pct.correcto_tree2 <- 100 * sum(diag(mat.confusion_tree2)) / sum(mat.confusion_tree2)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",
              pct.correcto_tree2))
print(paste0("El mejor parámetro para el árbol de clasificación ha sido: ",
             names(model_tree2$bestTune),"=", model_tree2$bestTune))

tabla.modelos[nrow(tabla.modelos)+1,] = c("Decision Tree 2", pct.correcto_tree2, sum(mat.confusion_tree2)-sum(diag(mat.confusion_tree2)))
```

**Matriz de confusión**

```{r warning=FALSE}
csstab_tree2 <- CrossTable(data_test$Survived, predict_tree2,
                           prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE, 
                           dnn = c('Reality', 'Prediction'))
plot_matriz_confusion(csstab_tree2)
```

**Importancia de las variables**
```{r warning=FALSE}

datosVarImp <- varImp(model_tree2)$importance %>% 
  as.data.frame() %>%
  rownames_to_column() %>%
  arrange(Overall)
datosVarImp$Variable <- reorder(datosVarImp$rowname, datosVarImp$Overall)
ggplot(datosVarImp)+
  geom_col(aes(x = Variable, y = Overall), fill="steelblue", color="blue")+
  coord_flip() + ggtitle("Importancia de las variables")

```

#### Random Forest\

Construimos un Random Forest, una combinación de árboles de predicción. Cada árbol utiliza muestras con reemplazo del conjunto de datos que se le pasa al modelo. Cada uno utiliza valores diferentes de variables, para dar opciones a algunas variables que podrían quedar eclipsadas por otras con más relevancia.

```{r warning=FALSE}

tctrl <- caret::trainControl(method = "repeatedcv",
                             number=10, repeats = 3)
model_rf <- caret::train(Survived ~ Sex+Parch+SibSp+Child+Age+Pclass, 
                         data = data_train, 
                         method = "rf", 
                         trControl = tctrl,
                         verbose = FALSE)
plot(model_rf)
```


**Matriz de confusión**
```{r warning=FALSE, echo=FALSE}
predict_rf <- predict(model_rf, data_test)
mat.confusion_rf <- table(data_test$Survived, predict_rf)
mat.confusion_rf
pct.correcto_rf<-100 * sum(diag(mat.confusion_rf)) / sum(mat.confusion_rf)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",
              pct.correcto_rf))
tabla.modelos[nrow(tabla.modelos)+1,] = c("Random Forest", pct.correcto_rf, sum(mat.confusion_rf)-sum(diag(mat.confusion_rf)))
```

```{r warning=FALSE, echo=FALSE}
csstab_rf <- CrossTable(data_test$Survived, predict_rf,
                        prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE, 
                        dnn = c('Reality', 'Prediction'))
plot_matriz_confusion(csstab_rf)
```

**Importancia de las variables**

```{r warning=FALSE, echo=FALSE}
datosVarImp <- varImp(model_rf)$importance %>% 
  as.data.frame() %>%
  rownames_to_column() %>%
  arrange(Overall)
datosVarImp$Variable <- reorder(datosVarImp$rowname, datosVarImp$Overall)
ggplot(datosVarImp)+
  geom_col(aes(x = Variable, y = Overall), fill="steelblue", color="blue")+
  coord_flip() + ggtitle("Importancia de las variables")
```


#### C5.0

C5.0 es el algoritmo sucesor de C4.5, publicado por John Ross Quinlan (1992), con el objetivo de crear árboles de clasificación. Entre sus características, destacan la capacidad para generar árboles de decisión simples, modelos basados en reglas, ensembles basados en boosting y asignación de distintos pesos a los errores. Este algoritmo ha resultado de una gran utilidad a la hora de crear modelos de clasificación y todas sus capacidades son accesibles mediante el paquete C50. Aunque comparte muchas características con los algoritmos de random forest y gradient boosting, cabe tener en cuenta algunas peculiaridades:

- La medida de pureza empleada para las divisiones del árbol es la entropía.

- El podado de los árboles se realiza por defecto, y el método empleado se conoce como pessimistic pruning.

- Los árboles se pueden convertir en modelos basados en reglas.

- Emplea un algoritmo de boosting más próximo a AdaBoost que a Gradient Boosting.

- Por defecto, el algoritmo de boosting se detiene si la incorporación de nuevos modelos no aporta un mínimo de mejora.

- Incorpora una estrategia para la selección de predictores (Winnowing) previo ajuste del modelo.

- Permite asignar diferente peso a cada tipo de error.


Creamos primero unas variables para simplificar el uso de los distintos modelos.
- trainX corresponde a los atributos **Sex**, **Parch**, **SibSp**, **Child**, **Age**, **Pclass** del dataframe sin la variable Survived (para el conjunto de train)
- trainy es el dataframe pero sólo con la variable Survived (para el conjunto de train)

- testX  corresponde a los atributos **Sex**, **Parch**, **SibSp**, **Child**, **Age**, **Pclass** del dataframe sin la variable Survived (para el conjunto de train)
- testy es el dataframe pero sólo con la variable Survived (para el conjunto de test)


```{r warning=FALSE} 
trainX <- data_train[, c("Sex","Parch","SibSp","Child","Age","Pclass")]
trainy <- data_train[, c("Survived")]
testX <- data_test[, c("Sex","Parch","SibSp","Child","Age","Pclass")]
testy <- data_test[, c("Survived")]
```

##### Importancia de los atributos\

Definimos primero las métricas que vamos a usar en los árboles C5.0 a la hora de mostrar la importancia de los atributos:

- Usage: porcentaje de observaciones de entrenamiento que caen en todos los nodos generados tras una división en el que ha participado el predictor. Por ejemplo, en el caso de un árbol simple, el predictor empleado en la primera decisión recibe automáticamente una importancia del 100%, ya que todas las observaciones de entrenamiento caen en uno de los dos nodos hijos generados. Otros predictores puede que participen con frecuencia en divisiones, pero si en los nodos hijos solo caen unas pocas observaciones, su importancia puede ser próxima a cero. En el caso de boosting, se promedia la importancia de cada predictor en todos los árboles que forman el ensemble.

- Splits: porcentaje de divisiones en las que participa cada predictor. No tiene en cuenta la importancia de la división.

```{r warning=FALSE, , echo=FALSE}
#Vamos a crear una función que nos simplifique la generación de gráficas sobre la importancia de los atributos en un modelo de árbol C5.0.
importancia <- function(fit_tree) {
  imp_usage <- C5imp(fit_tree, metric = "usage")
  imp_usage <- imp_usage %>%
                       rownames_to_column(var = "predictor")
  
  imp_splits <- C5imp(fit_tree, metric = "splits")
  imp_splits <- imp_splits %>%
                       rownames_to_column(var = "predictor")
  
  
  p1 <- ggplot(data = imp_usage, aes(x = reorder(predictor, Overall),
                                             y = Overall, fill = Overall)) +
      labs(x = "", title = "usage") +
      geom_col() +
      coord_flip() +
      scale_fill_viridis_c() +
      theme_bw() +
      theme(legend.position = "none")
  
  p2 <- ggplot(data = imp_splits, aes(x = reorder(predictor, Overall),
                                              y = Overall, fill = Overall)) +
      labs(x = "", title = "splits") +
      geom_col() +
      coord_flip() +
      scale_fill_viridis_c() +
      theme_bw() +
      theme(legend.position = "none")
  ggarrange(p1, p2)
}
```


```{r message= FALSE, warning=FALSE, echo=FALSE}
# funcion para generar la información de precisión y confusion
precision <- function(fit_tree, test_x, test_y, titulo) {
    predict_unseen <- predict(fit_tree, test_x, type = 'class')
    prec <- 100*sum(predict_unseen == test_y) / length(predict_unseen)
    print(sprintf("La precisión del árbol %s es: %.4f %%",titulo, prec))
    ct <- CrossTable(test_y, predict_unseen,
           prop.chisq = FALSE, 
           proc.c = FALSE, 
           prop.r = FALSE, 
           dnn = c('Reality', 'Prediction'))
    plot_matriz_confusion(ct)
    return(c(titulo, prec, length(predict_unseen)-sum(predict_unseen == test_y)))
}
```

##### Primer modelo c5.0\

Vamos a empezar realizando un primer modelo C5.0 con los valores por defecto y con las reglas:

```{r warning=FALSE}
bc_tree <- C50::C5.0(trainX, 
                     trainy,
                      rules=FALSE, 
                      control = C5.0Control(seed = 123)
                )
summary(bc_tree)
```
Aunque podríamos representar el árbol, nos han salido muchas reglas y es complicado de visualizar. Lo analizamos numéricamente.

Primero veamos visualmente la importancia de cada variable:


```{r warning=FALSE, echo= FALSE} 
importancia(bc_tree)
```

Está usando casi todas las variables, de ahí que nos salgan tantas reglas.

Vamos a ver la precisión del modelo

```{r warning=FALSE,  echo= FALSE}
tabla.modelos[nrow(tabla.modelos)+1,] <- precision(bc_tree, testX, testy, "C50 1")

```

##### Segundo modelo C5.0 con Winnowing\

Winnowing consiste en aplicar un algoritmo de clasificación (algoritmo Winnow) a los atributos para eliminar aquellos que sean de poca ayuda.

Es una selección de atributos que se realiza antes de la creación del modelo.

El conjunto de datos se divide por la mitad aleatoriamente y se crea un modelo inicial. Cada predictor se va quitando por turno y se analiza el efecto sobre la calidad del modelo (usando la otra mitad de la división aleatoria)

Se marcan los predictores si su eliminación no incrementa la tasa de error. El modelo final se calcula usando todos los conjuntos de datos usando sólo los predictores no marcados.

Se puede realizar winnowing en C5.0 simplemente usando un flag.

```{r warning=FALSE}
bc_winno_tree <- C50::C5.0(trainX, 
                           trainy,
                           rules   = TRUE,
                           control = C5.0Control(seed = 123, winnow = TRUE)
                    )
summary(bc_winno_tree)
```
Parece que en este caso no es capaz de eliminar atributos (winnow)

Vamos a ver cuantas variables ha utilizado ahora:

```{r warning=FALSE, echo = FALSE}
importancia(bc_winno_tree)
```


```{r warning=FALSE, echo= FALSE}
tabla.modelos[nrow(tabla.modelos)+1,]<- precision(bc_winno_tree, testX, testy, "C50 2")
```
No hemos mejorado los errores

##### Tercer modelo C5.0 usando boosting\

La implementación del C5.0 dispone de la posibilidad de aplicar un *Boosting* similar a *AdaBoost*, que permite combinar varios árboles (técnica de *Ensemble*) para producir mejores modelos predictivos que si sólamente usasemos un árbol de decisión simple.

Para ello se utiliza el parámetro ```trials```, en el que le indicamos cuantas iteraciones (que a la postre son árboles distintos) debe utilizar para generar el modelo *ensemble*.

Podríamos ir probando con distintos boosts variando el winnowing y los parámetros hasta encontrar el que mejor modelo nos generase.
Es una labor tediosa que podemos simplificar usando la librería ```caret```, que proporciona una forma de entrenar modelos modificando sus parámetros, vamos a usarlo para el C5.0  mostrando la comparativa posteriormente.

En este caso vamos a usar Cohen-Kappa como medición de calidad del modelo, y compararemos C5.0 generados con distintas iteraciones (boosting) combinándolo con winnowing y con rules/tree.

```{r warning=FALSE}
tuned <- train(trainX, trainy, method = "C5.0", tuneLength = 11,
         trControl = trainControl(method = "repeatedcv", repeats = 5, allowParallel = F),
         metric = "Kappa")
```

```{r warning=FALSE, echo= FALSE}
postResample(predict(tuned, testX), testy)
plot(tuned, metric = "Kappa")
```

Los valores anteriores son orientativos y nos sirven para acotar más fácilmente los parámetros en los que buscar.

Vamos a crear el mejor árbol sin winnowing y boost, usando 20 trials y sin reglas:

```{r warning=FALSE}
bc_boost_tree <- C50::C5.0(
                      trainX, 
                      trainy,
                      rules   = FALSE,
                      control = C5.0Control(seed = 123, winnow = FALSE),
                      trials = 20
                    )
```

Como antes, vemos la importancia de los atributos:

```{r warning=FALSE, echo= FALSE}
importancia(bc_boost_tree)
```
En este caso todos los atributos tienen un uso muy alto.

De nuevo calculamos matriz de confusión

```{r warning=FALSE,  echo= FALSE}
tabla.modelos[nrow(tabla.modelos)+1,] <- precision(bc_boost_tree, testX, testy, "C50 3")

```

\newpage
# Representación de los resultados a partir de tablas y gráficas.

Durante la resolución de la práctica hemos aprovechado las capacidades didácticas que ofrece el formato rmd. Se ha podido ir generando diversas gráficas y tablas en cada una de las secciones y explicando sus interpretaciones. Hemos incluido todo el código de la práctica a lo largo de este documento mostrándose los resultados de forma rápida y amena.
Hemos utilizado diversos tipos de gráficas en nuestro análisis exploratorio de las variables, durante la creación de nuevas, durante la elaboración de hipótesis de correlaciones entre variables y a la hora de mostrar los resultados de nuestros modelos.
Esto es especialmente relevante en el caso del análisis exploratorio pues a la hora de tomar decisiones de limpieza y de uso de variables, disponer de las gráficas en el momento de la decisión es muy útil.

Para entender mejor los modelos predictivos, se han ido también creando gráficas representando las tablas de confusión y extrayendo la precisión de los modelos.

En los árboles se han mostrado, cuando eran suficientemente pequeños, las representaciones gráficas de los mismos, y cuando no, se han mostrado datos y tablas numéricas explicando brevemente su utilidad.

A continuación, exponemos un resumen del comportamiento de los diferentes modelos predictivos creados a lo largo de la práctica:

```{r}
knitr::kable(tabla.modelos)
```

# Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

Hemos realizado, sobre el conjunto de datos del Titanic, las fases de limpieza, depuración y análisis de datos (eliminando variables innecesarias, imputando datos faltantes, comprobando hipótesis estadísticas), hasta finalmente implementar varios modelos de predicción.

El problema que nos planteábamos era: Dado el conjunto de datos que disponemos, ¿podemos predecir la supervivencia o no de un pasajero? Podemos ser optimistas respecto al resultado.

Podemos diferenciar entre las conclusiones del análisis exploratorio y la capacidad de predecir de los modelos creados. Del análisis exploratorio podríamos responder a la pregunta: ¿Importaba el sexo, la edad, la clase social para sobrevivir al naufragio del Titanic? Todo parece indicar que si, que tuvieron mayor proporción de supervivencia las mujeres, los niños y los ricos. Obviamente, no en todos los casos fue así, por eso no hemos encontrado un modelo predictivo con un alto nivel de precisión

Hemos creado diferentes modelos predictivos y los resultados de precisión han sido discretos:

- Destaca una regresión logística con una precisión del 85.58% (glm1), usando datos enriquecidos con variables sintéticas con 32 errores de predicción con los datos de tests.

- Ninguno de Los árboles de decisión planteados ha conseguido mejorar ese registro, quedándose como mejores dos c5.0 en un 81.53% de precision y 41 errores. El uso de un conjunto mas limitado de atributos tras el análisis previo, ha resultado en que la técnica de winnowing no mejore los resultados, pues todos los atributos son usados. Lo que si varía entre los distintos c5.0 es el balance entre los tipos de errores. Dado el tipo de problema que se plantea sería preferible quedarse con los modelos que fallan mas prediciendo más "no-supervivencia" (y luego si que sobreviven ) que los que fallan más prediciendo mas supervivencia y luego no sobreviven.

- La distribución de los fallos en el modelo de regresión logística ha sido que realmente fallecen el 9,49% y el modelo predice que sobreviven (y sobreviven el 22.35% y el modelo predice lo contrario). Si buscamos un modelo que se equivoque menos en la predicción de que sobrevive y luego no lo haga, podríamos usar el primer árbol de decisión que solo tiene un 2.92% de error en ese caso a costa de tener un 52.94% en los casos que predice que fallecen y realmente sobrevive.
Otra opción es parametrizar el C5.0 para que priorize tener menos errores del tipo predigo que fallece pero sobrevive. Aunque esto siempre será a costa de un mayor número de errores globales.


## Exportación de los datos

Durante esta práctica se generan dos ficheros que estarán disponibles en el repositorio github. Estos son los siguientes:

- Un fichero “titanic_final.csv” que contiene las 12 variables con las que se ha trabajado, con la imputación de los datos realizada, con aquellas variables no utilizadas del dataset origen eliminadas, y con las transformaciones que hemos considerado necesarias.

- Un fichero “titanic_predict.csv”, en el que además de las columnas que tiene el fichero anterior, tiene una columna nueva llamada “Survived_Predicted”, que es la columna con la predicción de la variable “Survived” realizada con el modelo escogido.

```{r warning=FALSE}

fichero.nuevo <- "titanic_final.csv"
write.csv(data, file=fichero.nuevo, row.names = FALSE)
#Realizamos la predicción con el modelo construido con rpart y el dataset total
predict_fin <-predict(modelo_glm1, data)

#Añadimos la columna de la prediccion al conjunto de datos anterior 
data$Survived_Predicted <- predict_fin
fichero.nuevo <- "titanic_predict.csv"
write.csv(data, file=fichero.nuevo, row.names = FALSE)

```

# Tabla de contribuciones

| Contribuciones              | Firma                                                | 
|-----------------------------|------------------------------------------            |
| Investigación Previa        | Alexis Germán Arroyo Peña, Gabriel Pulido de Torres  |
| Redacción de las respuestas | Alexis Germán Arroyo Peña, Gabriel Pulido de Torres  |
| Desarrollo código           | Alexis Germán Arroyo Peña, Gabriel Pulido de Torres  |

\newpage
# Bibliografía y referencias

[1] Arboles de decision, Random Forest, Gradient Boosting y C5.0. [en línea], [sin fecha]. [Consulta: 2 enero 2021]. Disponible en: https://www.cienciadedatos.net/documentos/33_arboles_decision_random_forest_gradient_boosting_c50#C50. 

[2] JARMAN, K.H., 2013. The Art of Data Analysis: How to Answer Almost Any Question Using Basic Statistics. S.l.: s.n. ISBN 9781118413357. 

[3] MAT, L.S., OSWALDO, D., MIREIA, T. y GONZ, C., [sin fecha]. Introducción a la limpieza y análisis de los datos. , 

[4] MOLINA, L.C. y SANGÜESA I SOLÉ, R., [sin fecha]. Módulo 8: Evaluación de modelos. UOC.
