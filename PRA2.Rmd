---
title: 'Tipologia y Ciclo de vida de los Datos. Practica 2'
author: "Autores: Alexis Germán Arroyo Peña y Gabriel Pulido de Torres"
date: "Enero 2021"
fontfamily: arev
output:
  pdf_document:
    highlight: zenburn
    toc: yes
    latex_engine: xelatex
    number_sections: true
    df_print: kable

  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: PRA-header.html
  word_document: default
---

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

```{r  message= FALSE, warning=FALSE, include=FALSE}
library(funModeling)
library(mice)
library(car)
library(gmodels)
library(kableExtra)
library(gridExtra)
library(grid)
library(nortest)
library(C50)
library(caret)
library(dplyr)
library(rpart)
library(rpart.plot)
library(tibble)
library(ggplot2)
library(ggpubr)
library(caTools)
library(factoextra)
library(corrplot)
library(knitr)
library(sqldf)
library(readr)
library(scales)
library(pROC)
library(xgboost)
library(randomForest)
library(rpart.plot)
library(tidyr)
library(beeswarm)

```

# Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?

Hemos optado por analizar el dataset de datos del titanic.

En este conjunto de datos tenemos información acerca de los pasajeros que iban en el Titanic, naufragado en 1912 y en el que murieron 1500 personas. Además de información descriptiva del tipo de pasajero tenemos también el indicador de si sobrevivió al hundimiento o no. El objetivo es decidir si las variables aportadas son suficientes para crear un modelo predictivo que prediga la supervivencia o no de un pasajero.

Realizamos un primer contacto con el conjunto de datos, visualizando su estructura.  

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos los paquetes R que vamos a usar


# Cargamos el fichero de datos
data <- read.csv('train.csv',stringsAsFactors = FALSE, na.strings = "")
dim.data.frame(data)

# Verificamos la estructura del conjunto de datos
str(data)
```
El conjunto de datos incluye 12 variables y 891 observaciones.

**Descripción del conjunto de datos:**

- Passengerld: 
  Contador de pasajeros del 1 al 891.

- Survived:
  esta variable toma dos valores e indica si el pasajero sobrevivió. (0= No, 1= Si).

- pClass:
  clase del ticket. 1=1st (clase alta), 2=2nd (clase media) y 3=3rd (clase baja).

- Name:
  nombre completo del pasajero.
  
- Sex:
  sexo del pasajero (Female o Male).
  
- Age:
  edad del pasajero
  
- SibSp:
  número de hermanos/hermanas, hermanastros/hermanastros y marido o esposa del pasajero que también iban a bordo.

- Parch:
  número de hijas, hijos, padre y madre del pasajero a bordo del Titanic.
  
- Ticket: 
  El número del ticket del pasajero.

- Fare:
  Es la tarifa del pasajero en dólares.

- Cabin:
  Código identificativo de la cabina.
  
- Embarked:
  el puerto en el que embarcó el pasajero (C = Cherbourg, Q =Queenstown, S = Southampton).

## Objetivo

El objetivo es decidir si las variables aportadas son suficientes para crear un modelo predictivo que prediga la supervivencia o no de un pasajero.

\newpage
# Integración y selección de los datos de interés a analizar.

Hemos leido los datos en un dataframe (al que llamamos "data"). Vemos su dimensionalidad, los nombres y tipos de las variables:

```{r message= FALSE, warning=FALSE}
dim.data.frame(data)
sapply(data, function(x) class(x))
```

Aprovechamos para comprobar si hay registros duplicados usando el comando unique()

```{r message= FALSE, warning=FALSE}
data_unique <- unique(data)
dim.data.frame(data_unique)
remove(data_unique)
```

Se comprueba que la dimensionalidad ha quedado exactamente igual que cuando cargamos el dataset, por lo tanto, no hay registros duplicados (nos referimos a completos duplicados).

Mostramos una muestra de los primeros registros de nuestro dataframe:

```{r message= FALSE, warning=FALSE}
summary(data)

df_status(data)
```

Hay algunas variables que carecen de interés por ser identificativas de cada registro. Se tratan de “PassengerId”, “Ticket” y “Name”. No nos interesa tener unívocamente identificado cada caso para realizar ningún tipo de análisis, no aportan nada. 

## PersonasTicket

Antes de eliminar la variable **Ticket**, nos va a servir para conocer el precio unitario que han pagado los pasajeros, ya que la variable **Fare** es la tarifa pagada en el ticket, pero dentro del mismo ticket pueden estar incluidas varias personas. Inicialmente vamos a obtener el número de personas que están incluidas en un mismo ticket.

```{r message= FALSE, warning=FALSE}
nrow(table(data$Ticket, data$Fare))
length(unique(data$Ticket))

data %>% group_by(Ticket, Fare) %>% filter(row_number() == 1)

```

Podemos obtener el precio por persona, dividiendo Fare / integrantes del ticket:

```{r message= FALSE, warning=FALSE}
ticket_personas <- as.data.frame(data %>% 
                                   group_by(Ticket) %>% 
                                   dplyr::summarize(PersonasTicket=n()))
```

Creamos un nuevo dataframe (llamado "ticket_personas") con las variables **Ticket** y **PersonasTicket** 

```{r message= FALSE, warning=FALSE}
df_status(ticket_personas)
```

Este nuevo dataframe lo combinamos con nuestro dataframe original (un join) a través del número de ticket (variable **Ticket**) para poder incorporar el número de personas al dataframe original. Después de juntarlos eliminamos el df ticket_personas pues no lo necesitaremos.

```{r message= FALSE, warning=FALSE}
data <- merge(data, ticket_personas, by = "Ticket")
remove(ticket_personas)
```

Ahora tenemos en nuestro dataframe original “data” una nueva variable “PersonasTicket”. Esa variable será utilizada para dividir la tarifa del ticket “Fare” entre esta nueva columna incorporada. Con ello obtenemos una nueva variable que le llamamos “Price” y es el precio por persona que se paga en el billete (obteniendo un precio por persona lineal por billete).

```{r message= FALSE, warning=FALSE}
data$Price <- data$Fare / data$PersonasTicket
```

Ahora ya podemos eliminar todas las variables que no vamos a necesitar: PassengerId, Name, Ticket, PersonasTicket:

```{r message= FALSE, warning=FALSE}
data <- select(data, -PassengerId, -Name, -Ticket, -PersonasTicket)
```

## FamilySize

Revisando **Parch** (número de Padres / hijos a bordo) y **SibSp** (sibling: número de hermanos, hermanas, hermanastros y hermanastras  del pasajero, spouse: Marido o mujer del pasajero en el titanic ) vemos que las podemos agregar en una nueva variable **FamilySize** que será la suma de estas dos variables mas el propio viajero en cuestion. Por ello esta variable como mínimo valdra uno.

```{r message= FALSE, warning=FALSE}
data$FamilySize = data$SibSp + data$Parch + 1
```

## Revisión y conversion de tipos

Tenemos algunas variables que, aunque a priori aparecen como “numeric” o “character” deberíamos convertir a “factor”. Estas variables son: “Survived”, “Pclass”, “Embarked” y “Sex”.
Tienen un número finito de valores y aunque puedan ser numéricas, ese número no nos aporta información con lo que los discretizamos convirtiendolos en factores:

```{r message= FALSE, warning=FALSE}
data$Sex <- as.factor(data$Sex)
data$Survived <- as.factor(data$Survived)
data$Pclass <- as.factor(data$Pclass)
data$Embarked <- as.factor(data$Embarked)

```

La variable **Cabin** es de tipo character, pero como vamos a eliminarla no haremos ninguna conversión.

Finalmente nos quedarían como variables numéricas: **Age**, **SubSp**, **Parch**, **FamilySize**, **Fare** y **Price**

```{r message= FALSE, warning=FALSE}
summary(data)
```


\newpage
# Limpieza de los datos.

Analizamos los valores nulos y vacíos. Para ello nos valemos de la salida de la función *df_status*, que no s muestra un resumen del estado de nuestras 8 variables actuales:

```{r message= FALSE, warning=FALSE}
df_status(data)
```

\newpage
## Elementos nulos y ceros. 

### Elementos nulos

```{r message= FALSE, warning=FALSE}
data %>% group_by(Embarked) %>% count(Embarked)
```



En la tabla se observa que el campo **Age** tiene un 19.87% de nulos, **Cabin** más de un 77% y dos nulos en **Embarked**

#### Embarked

Solo hay 2 valores nulos, al ser muy pocos casos y además la variable solo toma 3 posibles valores, imputamos el valor que mas se repite, que es Embarked=S (Southampton)

```{r message= FALSE, warning=FALSE}
data %>% group_by(Embarked) %>% count(Embarked)
data_Embarked <- sort(table(data$Embarked, useNA = "ifany"), decreasing = TRUE)
```

Gráficamente:

```{r message= FALSE, warning=FALSE}
dat_plot <- as.data.frame(data_Embarked)
ggplot(dat_plot, aes(x=Var1, y=Freq, fill=Var1)) +
  geom_bar(stat = "identity", color = "black") +
  geom_text(aes(label=Freq), vjust = -0.4, color="black", size=3) +
  labs(x='Embarked', y='Count') + 
  theme(legend.position = "none")
```

Asignamos el valor mas frecuente a los casos nulos:

```{r message= FALSE, warning=FALSE}
data$Embarked[is.na(data$Embarked)] <- names(data_Embarked[1])
```

#### Cabin

Dado que el número de nulos es muy elevado, un 77%, se opta por eliminar esta variable ya que tendríamos que imputar valores a una parte muy importante del dataset (con su consiguiente error). Además no parece que pueda ser una variable determinante para predecir la supervivencia.

```{r message= FALSE, warning=FALSE}
data <- select(data, -Cabin)
```


#### Age

Tiene mas del un 19% de calores nulos (concretamente 177 registros)

Una opción para solucionarlos sería calcular la media del resto de registros e imputarla, pero vamos a estudiar si podemos delimitar la media a aplicar para obtener un resultado más depurado.

Primero analizamos la distribución de la variable **Age** teniendo en cuenta sólo los registros donde hay valores (es decir algo mas del 80% del dataframe).
Para ello creamos un nuevo dataset sin los registros nulos de Age

```{r message= FALSE, warning=FALSE}
data_NoNA = data[which(!is.na(data$Age)),]
```

Observamos gráficamente como se distribuye la variable Age en este dataset:

```{r message= FALSE, warning=FALSE}
ggplot(data_NoNA, aes(Age))+
  geom_histogram(aes(y = ..density..), bins=50, fill="steelblue", color="blue") + 
  stat_function(fun = dnorm, args = list(mean = mean(data_NoNA$Age), sd = sd(data_NoNA$Age)))
```

Comprobamos si hay alguna relación entre la edad alguna del resto de variables, para tenerlo en cuenta a la hora de imputar valores

#### Age vs Sex

Comprobamos gráficamente la relación entre la edad y el género

```{r message= FALSE, warning=FALSE}
titulo <- 'Age vs Sex'
ggplot(data_NoNA, aes(y=Age, x=Sex, fill=Sex)) + geom_boxplot() + labs(title = paste0('Boxplot: ', titulo)) + ylab("Age") + xlab("Sex")
```

No se aprecian casi diferencias de edad en función del género

#### Age vs Embarked

Comprobamos gráficamente la relación entre la edad y el puerto de Embarque

```{r message= FALSE, warning=FALSE}
titulo <- 'Age vs Embarked'
ggplot(data_NoNA, aes(y=Age, x=Embarked, fill=Embarked)) + 
  geom_boxplot() + labs(title = paste0('Boxplot: ', titulo)) + ylab("Age") + xlab("Embarked")
```

Tampoco se aprecian diferencias significativas en este caso con respecto a las medias de edad en cada una de las clases de Embarked.

#### Age vs Pclass

Representamos visualmente la relación entre Age y Pclass:

```{r message= FALSE, warning=FALSE}
titulo <- 'Age vs Pclass'
ggplot(data_NoNA, aes(y=Age, x=Pclass, fill=Pclass)) + 
  geom_boxplot() + labs(title = paste0('Boxplot: ', titulo)) + ylab("Age") + xlab("Pclass")
```

En este caso si se observa una relación entre la edad y la clase en que viajaban los pasajeros: Los pasajeros de clase 1 (alta) tenían generalmente mayor edad que los de clase 2 (media) e igualmente sucede con los de clase 3 (baja). 

#### Age vs Variables numéricas

```{r message= FALSE, warning=FALSE}
lista<-sapply(data, is.numeric) 
data_num_NoNA = data_NoNA[,lista]
corrplot(cor(data_num_NoNA), method="number")
corrplot.mixed(cor(data_num_NoNA))
```

Se observa que existe correlación negativa con **SibSp** y con **Parch** (también con **FamilySize**, pero eso es completamente normal porque **FamilySize** es una transformación lineal de las otras 2). También hay correlación positiva con **Price**, pero entendemos que podemos tener en cuenta la parte familiar por el tema de esposa, hijos, hermanos, etc. puede tener efecto en la edad.

#### Imputación de valores a Age

Tras el análisis de las diversas relaciones entre las variables y Age vamos a realizar cuatro simulaciones diferentes de imputación y nos quedaremos con una sola:

- Caso 1: Imputar la media de **Age** a todos los elementos faltantes

```{r message= FALSE, warning=FALSE}
data$Age1 <- data$Age
data$Age1[is.na(data$Age1)] <- mean(data_NoNA$Age)

ggplot(data, aes(Age1)) +
  geom_histogram(aes(y = ..density..), bins=50, fill="steelblue", color="blue") + 
  stat_function(fun = dnorm, args = list(mean = mean(data$Age1), sd = sd(data$Age1)))
```


- Caso 2: Imputar la media de **Age** pero por cada una de las clases(“Pclass”) ya que hemos visto que hay una relación entre ambas variables.

```{r message= FALSE, warning=FALSE}
data$Age2 <- data$Age
data$Age2[is.na(data$Age2)&data$Pclass == 1] <- mean(data$Age2[!is.na(data$Age2)&data$Pclass == 1])
data$Age2[is.na(data$Age2)&data$Pclass == 2] <- mean(data$Age2[!is.na(data$Age2)&data$Pclass == 2])
data$Age2[is.na(data$Age2)&data$Pclass == 3] <- mean(data$Age2[!is.na(data$Age2)&data$Pclass == 3])

ggplot(data, aes(Age2)) +
  geom_histogram(aes(y = ..density..), bins=50, fill="steelblue", color="blue") + 
  stat_function(fun = dnorm, args = list(mean = mean(data$Age2), sd = sd(data$Age2)))
```

- Caso 3: Imputar la datos en **Age**, pero teniendo en cuenta **Pclass**, **Parch** y **SibSp**, ya que hemos visto correlación entre las variables. Para este caso lo que hacemos es tener en cuenta las 3 variables y generar una agrupación de datos calculando la media para las combinaciones (recordemos que son variables discretas). Una vez que obtenemos esos valores medios, los imputamos. Luego verificamos si quedó algún valor sin imputar (que serán muy pocos) y para esos pocos casos faltantes, imputar los valores por cada clase.

```{r message= FALSE, warning=FALSE}
medias_clase_fam <- as.data.frame(data_NoNA %>% group_by(Pclass, SibSp, Parch) %>% dplyr::summarize(Media_clase_fam = mean(Age)))
```

Hacemos un meMerge entre nuestro dataset original y el de Medias (por Pclass, SIbSp y Parch) a través de las columnas usadas en la agrupación.
El merge e sun LEFT JOIN ya que puede que no existan todas las combinaciones en medias_clase_fam

```{r message= FALSE, warning=FALSE}
data$Age3 <- data$Age
data <- merge(data, medias_clase_fam, by = c("Pclass", "SibSp", "Parch"), all.x = TRUE)
data$Age3[is.na(data$Age3)] <- data$Media_clase_fam[is.na(data$Age3)]
```

Como es posible que nos hayan quedado alguno sin poder asignar (al no existir la combinación Pclass + sibSp + Parch) a los que faltan (que son 7) les asignamos directamente por la Pclass sin tener en cuenta los otros valores

```{r message= FALSE, warning=FALSE}
data$Age3[is.na(data$Age3)&data$Pclass == 1] <- mean(data$Age3[!is.na(data$Age3)&data$Pclass == 1])
data$Age3[is.na(data$Age3)&data$Pclass == 2] <- mean(data$Age3[!is.na(data$Age3)&data$Pclass == 2])
data$Age3[is.na(data$Age3)&data$Pclass == 3] <- mean(data$Age3[!is.na(data$Age3)&data$Pclass == 3])
```

Vemos ahora la distribución que nos queda

```{r message= FALSE, warning=FALSE}
ggplot(data, aes(Age3)) +
  geom_histogram(aes(y = ..density..), bins=50, fill="steelblue", color="blue") + 
  stat_function(fun = dnorm, args = list(mean = mean(data$Age3), sd = sd(data$Age3)))
```

- Caso 4: Imputando datos de **Age**, con MICE (Multivariate Imputation via Chained Equations). En este caso se predicen los valores de **Age**, con el resto de valores observados (usamos para este caso **Pclass**, **SibSp**, **Parch**, **Sex** y **Age**).

```{r message= FALSE, warning=FALSE}
columnas <- c('Pclass', 'SibSp', 'Parch', 'Sex', 'Age')

mice_imputar <- mice(data = data[, columnas], method = "rf")
#mice_imputar <-  parlmice(data = data[, columnas], method = "rf", n.core = 8, n.imp.core = 50)
mice_completo <- mice::complete(mice_imputar)
data$Age4 <- data$Age
data$Age4[is.na(data$Age4)]<- mice_completo$Age[is.na(data$Age4)]
```

Tras la imputación observamos la gráfica:

```{r message= FALSE, warning=FALSE}
ggplot(data, aes(Age4)) +
  geom_histogram(aes(y = ..density..), bins=50, fill="steelblue", color="blue") + 
  stat_function(fun = dnorm, args = list(mean = mean(data$Age4), sd = sd(data$Age4)))
```

Resumiendo el resultado de las 4 opciones de imputación mas la original:

```{r message= FALSE, warning=FALSE}
summary(data$Age)
summary(data$Age1)
summary(data$Age2)
summary(data$Age3)
summary(data$Age4)
```

Tras ver los resultados nos decantamos por la cuarta opción (Age4), ya que la distribución se parece mucho más
a la original.
Asignamos y limpiamos el dataset:

```{r message= FALSE, warning=FALSE}
data$Age <- data$Age4
data <- select(data, -Age1, -Age2, -Age3, -Age4, -Media_clase_fam)
```


### Ceros 

Recordamos los valores con ceros del dataset

```{r message= FALSE, warning=FALSE}
df_status(data)
```


Tenemos un alto número de ceros en **SibSp** y **Parch**, pero son valores válidos para estas variables, pues cuentan el número de acompañantes (familiares) del pasajero. Hay también un porcentaje  pequeño de ceros en **Fare** (tarifa), esto podría tener algún sentido (por ejemplo, tickets sin coste por ser un premio o un regalo) por lo que, en principio, vamos a dejar presentes estos ceros.


### Conclusión limpieza nulos y ceros

Viendo nuevamente los resultados con **summary**, hemos eliminado los nulos y tenemos un nuevo valor de media y mediana para **Age**

```{r message= FALSE, warning=FALSE}
summary(data)
```

Y con “df_status” vemos también como nos han quedado los datos después de eliminar variables, y de imputar valores en las variables que le faltaban algunos valores. El dataset queda libre de nulos, y con los ceros que hemos
aceptado que tiene que mantener y que tienen sentido.

```{r message= FALSE, warning=FALSE}
df_status(data)
```

## Identificación y tratamiento de valores extremos.

Se considera un valor extremo, outlier, a un valor fuera de rango. Son valores que se salen de la escala esperada visualizando el resto de las observaciones. En la actualidad, el criterio más habitual es considerar un valor extremo
a aquel que se encuentra alejado de la media unas tres veces la desviación típica.
En nuestro caso vamos a comenzar por separar aquellas variables que son numéricas y verlas en un gráfico bloxplot:

## Gráfico boxplot variables numéricas
 
```{r message= FALSE, warning=FALSE}
lista<-sapply(data, is.numeric) 
data_num<-data[,lista] 
boxplot(data_num,las=2)
var.continuas <- vector()
```

De todas las variables numéricas sólo 3 son contínuas: **Age**, **Price** y **Fare**

Analicemos esas tres variables por separado

### Fare

El boxplot parece indicar que Fare tiene valores extremos. Los identificamos usando el criterio de tres veces la desviación típica:

```{r message= FALSE, warning=FALSE}
data_out <- as.data.frame(data$Fare)
data_out$outlier <- FALSE
for (i in 1:ncol(data_out) - 1){
  columna = data_out[, i]
  if (is.numeric(columna)) {
    media = mean(columna)
    desviacion = sd(columna)
    data_out$outlier = (columna> (media+3*desviacion) | columna<(media-3*desviacion))
  }
}
table(data_out$outlier)
```

Con este criterio tenemos identificados 20 posibles outliers, observando mas detenidamente los valores que nos indica boxplot.stats y teniend en cuenta que el máximo es 512, no parecen exagerados:

```{r message= FALSE, warning=FALSE}
boxplot.stats(data$Fare)$out
```

Los valores, además, están bien distribuidos, los más altos en las clases altas.

Por todo esto, decidimos no realizar ninguna acción con estos outliers ya que incluso ueden estar aportando información importante:

## Gráfico outlier Fare

```{r message= FALSE, warning=FALSE}
boxplot(data$Fare~data$Pclass,xlab="Pclass",ylab="Fare",
        col=c("blue","yellow","red"))
```

### Price

Hacemos un análisis similar al realizado con  Fare:

```{r message= FALSE, warning=FALSE}
data_out <- as.data.frame(data$Price)
data_out$outlier <- FALSE
for (i in 1:ncol(data_out) - 1){
  columna = data_out[, i]
  if (is.numeric(columna)) {
    media = mean(columna)
    desviacion = sd(columna)
    data_out$outlier = (columna> (media+3*desviacion) | columna<(media-3*desviacion))
  }
}
table(data_out$outlier)
```

De nuevo con boxplot.stats analizamos los outliers, el valor máximo 221:

```{r message= FALSE, warning=FALSE}
boxplot.stats(data$Price)$out
```

Y al igual que con **Fare**, los valores más altos en las clases altas:

##Gráfico boxplot Fare

```{r message= FALSE, warning=FALSE}
boxplot(data$Price~data$Pclass,xlab="Pclass",ylab="Price",col=c("blue","yellow","red"))
```

Al igual que con **Fare** optamos por considerarlos valores válidos y no realizamos ninguna accion.

### Age

De nuevo realizamos el mismo procedimiento que con las otras dos variables

```{r message= FALSE, warning=FALSE}
data_out <- as.data.frame(data$Age)
data_out$outlier <- FALSE
for (i in 1:ncol(data_out) - 1){
  columna = data_out[, i]
  if (is.numeric(columna)) {
    media = mean(columna)
    desviacion = sd(columna)
    data_out$outlier = (columna> (media+3*desviacion) | columna<(media-3*desviacion))
  }
}
table(data_out$outlier)
```

y el resultado de boxplot.stats


```{r message= FALSE, warning=FALSE}
boxplot.stats(data$Age)$out
```

Donde vemos que podríamos tener 2 valores outliers, pero observando los valores devueltos por boxplot.stats que son totalmente normales no los vamos a considerar outliers.

\newpage
# Análisis de los datos.

## Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).


Del dataset completo nos interesa poder realizar diferentes análisis en función de diferentes subconjuntos de datos, como puede ser el género, la clase en la que viajan los pasajeros, el puerto en el que han embarcado, incluso
se pueden definir grupos por edad, y ver realmente si es cierto y se cumplió aquello que dicen en las películas “las mujeres y los niños primero” y poder comprobar si realmente los niños tienen mejor índice de supervivencia que los
adultos.
Podemos definir diferentes agrupaciones que podemos usar más adelante para estudiar los casos por grupos

### Niños

Vamos a definir una variable Child para aquellso registros en los que la edad sea menor que 8

```{r message= FALSE, warning=FALSE}
edad_corte = 8
data$Child[data$Age <= edad_corte] <- 1
data$Child[data$Age > edad_corte] <- 0
data$Child <- as.factor((data$Child))
```

### Género

Agrupamos por el género, creando una variable para cada uno de los géneros

```{r message= FALSE, warning=FALSE}
Mujeres <- data[which(data$Sex == 'female'),]
Hombres <- data[which(data$Sex == 'male'),]
```


### Lugar de embarque

Agrupamos por el lugar de embarque creando una variable por cada uno de los lugares

```{r message= FALSE, warning=FALSE}
EmbarqueC <- data[which(data$Embarked == 'C'),]
EmbarqueQ <- data[which(data$Embarked == 'Q'),]
EmbarqueS <- data[which(data$Embarked == 'S'),]

```

### Clase
Agrupamos por clase

```{r message= FALSE, warning=FALSE}
FirstClass <- data[which(data$Pclass == 1),]
SecondClass <- data[which(data$Pclass == 2),]
ThirdClass <- data[which(data$Pclass == 3),]
```

### Edades

Vamos a discretizar los valores por grupos de edades, añadiendo una columan al dataset (AgeInterval)

```{r message= FALSE, warning=FALSE}
data["AgeInterval"] <- cut(data$Age, breaks = c(0,13,18,40,55, 100), labels = c("0-12", "13-17", "18-39","40-54", "55-100"))
#intervalos_edad <- c(0,13,18,40,55)
#data$AgeInterval <- findInterval(data$Age, intervalos_edad)
data$AgeInterval <- as.factor(data$AgeInterval)
table(data$AgeInterval)
plot(data$AgeInterval)
```


## Comprobación de la normalidad y homogeneidad de la varianza.

### Normalidad

Vamos a verificar si las variables cuantitativas continuas siguen una distribución normal. Algunos test estadísticos requieren que las variables que van a ser analizadas sigan una distribución normal, por tanto tenemos que conocer cuáles son las distribuciones de nuestras variables continuas.
Las únicas variables cuantitativas continuas que tenemos en el dataset original son las variables **Age** y **Fare**. Además, hemos generado una nueva variable a partir de **Fare**, que hemos llamado **Price**, y que, por tanto también es una variable cualitativa continua. 

En general, la prueba de *Shapiro-Wilk* se considera una prueba muy potente para contrastar la normalidad de distribuciones. Se asume como hipótesis nula que la población sigue una distribución normal. Si el p-valor obtenido es inferior al nivel de significancia (normalmente α = 0,05) entonces se rechaza la hipótesis nula (y por tanto se concluye que los datos no vienen de una distribución normal). En cambio, si el p-valor es superior al nivel de significancia,
entonces no se puede rechazar la hipótesis nula y se asume que los datos
siguen una distribución normal.
Para poder tener más seguridad, vamos a aplicar otros dos métodos, la prueba de *Anderson-Darling* y la prueba de *Kolmogorov-Smirnov* (conocida también como K-S)

Creamos un data frame para resumir los tests:

```{r message= FALSE, warning=FALSE}
tabla.normalidad <- data.frame('variable' = character(),
                               'Test de Normalidad' = character(),
                               'Valor Estadístico' = numeric(),
                               'p-value' = numeric(),
                               stringsAsFactors = FALSE) 
str(tabla.normalidad)
```
Ahora recorremos todas las variables continuas aplicando los tres tests y añadiéndolos al dataframe:

```{r message= FALSE, warning=FALSE}
var.continuas <-c("Age", "Fare", "Price")

for (i in 1:length(var.continuas)){
  variable = var.continuas[i]
  #Test Shapiro-wil
  test = shapiro.test(data[,variable])
  tabla.normalidad[nrow(tabla.normalidad)+1,] = c(variable, test$method, test$statistic, test$p.value)
  
  #Test Anderson-Darling
  test = ad.test(data[,variable])
  tabla.normalidad[nrow(tabla.normalidad)+1,] = c(variable, test$method, test$statistic, test$p.value)
  
  #Test Kolmogorov-Smirnov
  test = ks.test(data[,variable], "pnorm", mean=mean(data[,variable]), sd=sd(data[,variable]))
  tabla.normalidad[nrow(tabla.normalidad)+1,] = c(variable, test$method, test$statistic, test$p.value)
}

knitr::kable(tabla.normalidad)
```

Con estos resultados se puede decir que ninguna de las 3 variables sigue una distribución normal, en todos los casos el p-value ha sido inferior a 0.05 y
por tanto se han rechazado la hipótesis nula (que la variable sigue una distribución normal).

No obstante, vamos a revisar gráficamente la distribución de cada una de las variables usando su histograma, curva de densidad y gráficas Q-Q

```{r message= FALSE, warning=FALSE}
for (i in 1:length(var.continuas)) {
  variable=var.continuas[i]
  #Histograma
  print(ggplot(data, aes(data[,variable])) + 
          geom_histogram(aes(y = ..density..), bins=50, fill="steelblue", color="blue") + xlab(variable) +
          stat_function(fun = dnorm, args = list(mean = mean(data[,variable]), sd = sd(data[,variable]))))
  #Gráfica Q-Q
  qqnorm(data[,variable], main=paste0('Normal Q-Q Plot ', '(Variable "', variable,'")'))
  qqline(data[,variable], col=2)
  
  print(variable)
}
```

### Homocedasticidad (comprobación de varianzas)

Cuando comparamos varianzas lo que estamos comprobando es que las varianzas entre los grupos a comparar son iguales.
Si los datos siguen una distribución normal, podemos usar el test de Levene, en caso contrario podemos usar por ejemplo el test de Fligner-Killeen, que es la alternativa no paramétrica que se utiliza cuando los datos no siguen una distribución normal ( o cuando hay problemas con outliers no resueltos)

En ambos test (Levene y Fligner-Killeen), la hipótesis nula asume la igualdad de varianzas en los diferentes grupos de datos, con lo que si el p-valor obtenido es inferior al nivel de significancia (generalmente alpha = 0,05) se rechaza la hipótesis nula y se concluye que hay heterocedasticidad.

#### Age

La variable Age está próxima a una distribución normal por lo cual podemos utilizar el test de Levene para la comprobación de varianzas.


##### Age con Survived

Primero analizamos si las varianzas son iguales cuando comprobamos **Age** y el grupo es **Survived**, es decir estamos comprobando la homogeneidad de varianzas de la edad en los grupos de supervivientes y no supervivientes.

```{r message= FALSE, warning=FALSE}
leveneTest(data = data, Age ~ Survived, center = mean)
```
En este caso el p-value es superior a 0.05 y por tanto asumimos que hay homogeneidad de varianzas entre los grupos


## Representación muestras forma gráfica

```{r message= FALSE, warning=FALSE}

colores_defecto_ggplot = (hue_pal()(2))
ggplot(data, aes(x = Survived, y = Age)) +
  geom_jitter(aes(color=Survived), position = position_jitter(0.05)) +
  scale_color_manual(values = colores_defecto_ggplot) + 
  scale_x_discrete(name="Survived", breaks=c("0", "1"), labels=c("No", "Yes"))
fligner.test(Age ~ Survived, data=data)

```

##### Age con Embarked

Ahora Comprobamos también cómo se comportan las varianzas cuando se trata de la variable edad “Age” con “Embarked”.

```{r message= FALSE, warning=FALSE}
leveneTest(data = data, Age ~ Embarked, center = mean)
```
En este caso hay omogeneidad de varianzas de Age en los grupos que define la variable Embarked

##### Age con Pclass
Ahora Comprobamos también cómo se comportan las varianzas cuando se trata de la variable edad “Age” con “Pclass”.
En este caso vamos a aplicar tanto el test de Levene como el de Fligner-Killeen:


```{r message= FALSE, warning=FALSE}
leveneTest(data = data, Age ~ Pclass, center = mean)
fligner.test(Age ~ Pclass, data = data)
```
En los dos tests (parmétrico y no paramétrico), se rechaza la hipótesis nula, con lo que hay heterogeneidad d varianzas entre las muestras de **Age**  cuando se agrupan por **Pclass**

##### Age con Sex

```{r message= FALSE, warning=FALSE}
leveneTest(data = data, Age ~ Sex, center = mean)
fligner.test(Age ~ Sex, data = data)
```

En los dos tests el p-value es claramente superior a 0.05 por lo que podemos afirmar que sí hay homogeneidad de varianzas para *Age* cuando está agrupado por *Sex*

#### Fare

Hacemos el mismo estudio con la variable Fare pero usando Fligner

```{r message= FALSE, warning=FALSE}
fligner.test(Fare ~ Sex, data = data)
fligner.test(Fare ~ Survived, data = data)
fligner.test(Fare ~ Embarked, data = data)
fligner.test(Fare ~ Pclass, data = data)
```

Comprobamos la variable “Fare”, los resultados indican que hay heterogeneidad de varianza de esas variables respecto a los grupos con los que se ha aplicado el test no paramétrico.


## Aplicación de pruebas estadísticas para comparar los grupos de datos. 

### Análisis de relaciones entre variables

Primero vamos a realizar diversos análisis de relaciones variables (principalmente pares de variables), para aclarar la dependencia entre ellas y como pueden afectar a las posibilidades de supervivencia

#### Age y Sex
Primero vamos a analizar si hay diferencias significativas entre la media de edad de mujeres y de hombres.
Para hacerlo aplicamos el test paramétrico t-test de Student, que requiere que las muestras a comparar sigan una distribución normal.
Ya vimos que **Age** no sigue exactamente una distribución normal, pero si consideramos el teorema central del límite con una muestra suficientemente grande (mayor de 30) se puede asumir que la variable sigue una distribución normal. Si la variable no siguiese una distribución normal habríamos aplicado una prueba no paramétrica como por ejemplo el test de Mann-Whitney.

Para ejecutar la prueba t de Student, disponemos en R del comando "t.test". Este mismo comando nos permite realizar el test de Welch cuando las varianzas entre las muestras son diferentes. 
Comprobemos que la variable **Age** sigue una distribución normal primero aplicando el F-test mediante el comando var.test

```{r message= FALSE, warning=FALSE}
var.test(Mujeres$Age, Hombres$Age)
```

El resultado nos indica que las varianzas de edad en los grupos de mujeres y hombres son iguales.

Aplicamos ahora un test para comparar las medias de los 2 grupos, la hipótesis nula será que no hay diferencias significativas entre la media de edades para hombres y mujeres. Podemos usar el t-Test indicando que las varianzas de los grupos son iguales (por el resultado anterior).

```{r message= FALSE, warning=FALSE}
t.test(Mujeres$Age, Hombres$Age, var.equal = TRUE)
```

El valor de p-values es inferior a 0.05, por lo que rechazamos la hipótesis nula. Es decir, **la media de edad por género tiene una diferencia significativa**.

Esstablecemos una nueva hipótesis alternativa: que la media de edad de las mujeres es menor que la de los hombres. Por lo tanto, la hipótesis nula corresponde a que la edad de las mujeres es mayor o igual a la de los hombres:

```{r message= FALSE, warning=FALSE}
t.test(Mujeres$Age, Hombres$Age, alternative = "less", var.equal = TRUE)
```
Con un p-value menor de 0.5 volvemos a rechazar la hipótesis nula, es decir, podemos afirmar que la media de edad de las mujeres del Titanic es inferior a la media de edad de los hombres a bordo.

#### Survival y Sex

Si hacemos una inspección visual de la relación entre las dos variables:

```{r message= FALSE, warning=FALSE}
ggplot(data,aes(x=Sex,fill=Survived))+geom_bar()
```

Parece indicar que ser mujer tenía mas posibilidades de supervivencia que siendo hombre.
Vamos a confirmar esto realizando algunos contrastes de hipótesis.


Primero, vamos a comprobar la relación entre la supervivencia y el género, analizando si el género fue un factor importante a la hora de la supervivencia, o dicho de otro modo, si dependiendo de si se era mujer u hombre las posibilidades de supervivencia cambiaban significativamente.
Para hacerlo aplicamos el test exacto de Fisher que analiza tablas de contigencia. En este caso la hipótesis nula es que la proporción de mujeres que mueren coincide con la proporción de hombre que mueren en el accidente del Titanic.

```{r message= FALSE, warning=FALSE}
fisher.test(table(data$Sex, data$Survived))
```

El resultado no deja lugar a dudas con un p-valor < 0.05 rechazamos la hipótesis nula, es decir: **hay diferente proporción de supervivencia entre hombres y mujeres.**

Una vez confirmado que el género si que es importante a ala hora de las probabilidades de supervivencia, vamos a ver quien tiene mas probabilidades de supervivencia, si las mujeres o los hombres. Para ello añadimos una condición a la hipótesis alternativa, usamos “less” para indicar (en la hipótesis nula) que el primer grupo (en este caso las mujeres ya que en orden alfabético es female y male) tiene menor proporción (probabilidad) si se rechaza la hipótesis nula. Es decir, la hipótesis nula dice que “la proporción de mujeres que mueren es mayor que la de los hombres”.

```{r message= FALSE, warning=FALSE}
fisher.test(table(data$Sex, data$Survived), alternative = 'less')
```

De nuevo rechazamos la hiótesis nula (p-value inferior a 0.05) con lo que se cumple la hipótesis alternativa: **la proporción de mujeres que mueren es inferior a la de los hombres**.

Si tenemos en cuenta que la tabla de contingencia que estamos evaluando es la siguiente:

```{r message= FALSE, warning=FALSE}
table(data$Sex, data$Survived)
```

El odd ratio de la tabla de contigengica lo calculamos así:

```{r message= FALSE, warning=FALSE}
tab.contigencia = table(data$Sex, data$Survived)
odd_ratio = (tab.contigencia[1,1] / tab.contigencia[1,2]) /
  (tab.contigencia[2,1] / tab.contigencia[2,2])
odd_ratio
```

Como vimos antes en el test de Fisher, la hipótesis alternativa se hace verdadera cuando el odd_ratio se vuelve 1. Luego cuando a la hipótesis alternativa le ponemos “less”, esta se hace verdadera cuando odd_ratio es menor que 1. Y si ponemos “greater” la hipótesis alternativa se hace verdadera si el odd_ratio es mayor que 1.

Podemos obtener intervalos de confianza, por ejemplo, al 99% de que la media de las edades de diferentes muestras, van a estar entre los valores 28.8 y 31.26 de media de edad.

```{r message= FALSE, warning=FALSE}
test = t.test(data$Age, conf.level = 0.99)
test$conf.int
```

#### Survival y Pclass 

De nuevo hacemos una primera inspección visual

```{r message= FALSE, warning=FALSE}
ggplot(data,aes(x=Pclass,fill=Survived))+geom_bar()
```

En el gráfico se aprecia claramente que el porcentaje de supervivencia por clases disminuye desde la primera hasta la tercera clase.

Para realizar el análisis numéricamente, al ser dos variables categóricas vamos a aplicar por ejemplo el test Chi-Cuadrado. Aquí la hipótesis nula nos dice que las variables son independientes. Vamos a comprobarlo:

```{r message= FALSE, warning=FALSE}
test_chisq <- chisq.test(data$Pclass, data$Survived)
test_chisq
```

El p-value obtenido es inferior a 0.05, es decir, rechazamos la hipótesis nula, y por tanto afirmamos que las variables no son independientes. Esto quiere decir que el grado de supervivencia era distinto dependiendo de la clase en la que estuvieses embarcado. Confirma el análisis visual, que nos aporta también que las clases con mas superviencia eran las mejores.

También se puede observar el valor de df que son los grados de libertad, que lo podemos obtener a través de la tabla de contingencias y el estadístico de contraste. Si el estadístico de contraste obtenido supera el valor crítico entonces se rechaza la hipótesis nula.

```{r message= FALSE, warning=FALSE}
df_chisq <- (length(levels(data$Pclass)) -1 ) * (length(levels(data$Survived)) - 1)
valorcritico_chisq <- qchisq(p=0.05, df = df_chisq, lower.tail = FALSE)
cat(sprintf("El estadístico obtenido es: %f y el valor crítico es: %f", test_chisq$statistic, valorcritico_chisq))
```

#### Survived y Embarked

Realizamos el mismo análisis

```{r message= FALSE, warning=FALSE}
ggplot(data,aes(x=Embarked,fill=Survived))+geom_bar()
```

El gráfico parece indicar que los embarcados en Southampton tenían menos posibilidades de sobrevivir. Puede ser que esté relacionado con la Pclass de cada lugar de embarque:

```{r message= FALSE, warning=FALSE}
ggplot(data,aes(x=Pclass,fill=Survived))+geom_bar()+facet_wrap(~Embarked)
```
Este nos confirma los embarcados en S eran mayoritariamente de clase 3 por lo que tiene sentido que su ratio de supervivencia sea menor.

Vemos ahora el análisis con contrastes de hipótesis.

Primero analizamos si hay relación entre las variables **Embarked** y **Survived** usando de nuevo la Chi-Squared

```{r message= FALSE, warning=FALSE}
test_chisq <- chisq.test(data$Embarked, data$Survived)
test_chisq
df_chisq <- (length(levels(data$Embarked)) -1 ) * (length(levels(data$Survived)) - 1)
valorcritico_chisq <- qchisq(p=0.05, df = df_chisq, lower.tail = FALSE)
cat(sprintf("El estadístico obtenido es: %f y el valor crítico es: %f", test_chisq$statistic, valorcritico_chisq))
```

De nuevo se rechaza la hipótesis nula, por lo tanto las variables son dependientes.

#### Survived y Child 

Analizamos ahora la nueva variable creada **Child** que corresponde a los niños de edad menor o igual a 8 años (que es un 1 en el valor de la clase)

De nuevo un análisis visual primero:

```{r message= FALSE, warning=FALSE}
ggplot(data,aes(x=Child,fill=Survived))+geom_bar(position ='fill')
```
Parece que si que hay mas esperanza de supervivencia en ese caso.

Aplicamos el test de Fisher para comprobar si tienen las mismas probabilidades de supervivencia que el resto de pasajeros. 

```{r message= FALSE, warning=FALSE}
fisher.test(table(data$Child, data$Survived))
```

Se rechaza la hipótesis nula, es decir que las propociones no coinciden. Analizamos ahora si las probabilidades de supervivencia son mayores o menores. Para ello analizamos si la proporcion de no-niños que no sobreviven es menor a la proporoción de niños que no sobreviven:

```{r message= FALSE, warning=FALSE}
fisher.test(table(data$Child, data$Survived), alternative = 'greater')
```
Se rechaza la hipótesis nula, y se acepta la alternativa, es decir que la probabilidad de muerte de los no-niños es mayor que la de los niños.

```{r message= FALSE, warning=FALSE}
tab.contigencia = table(data$Child, data$Survived)
tab.contigencia
odd_ratio = (tab.contigencia[1,1] / tab.contigencia[1,2]) /
  (tab.contigencia[2,1] / tab.contigencia[2,2])
odd_ratio
```

#### Survived y Age

Vamos a analizar ahora si la media de edad de las personas que murieron es coincidente con la media de edad que sobrevivieron.
Aplicamos el test t-Test

```{r message= FALSE, warning=FALSE}
t.test(data$Age[which(data$Survived==0)], data$Age[which(data$Survived == 1)])
```

Se observa que el p-valor es inferior a 0.05, con lo que rechazamos la hipótesis nula (que las medias de edad son coincidentes para fallecidos y supervivientes), pero como ya sabíamos, la distribución de Age no sigue una normal, por lo que vamos a aplicar el test no paramétrico U de Mann-Whitney

```{r message= FALSE, warning=FALSE}
wilcox.test(x = data$Age[which(data$Survived==0)],
            y = data$Age[which(data$Survived==1)],
            paired =FALSE
            )
```

La prueba no-paramétrica nos devuelve un p-value por encima de 0.05 y por tanto no rechazamos la hipótesis nula, con lo que podemos decir que la media de edad es coincidente entre los muertos y los supervivientes del accidente del Titanic.

Gráficamente podemos comprobarlo mediante un Boxplot

```{r message= FALSE, warning=FALSE}
colores_defecto_ggplot = (hue_pal()(2))
ggplot(data, aes(x=Survived, y=Age)) +
  scale_x_discrete(name = "Survived", labels = c("0"="no", "1"="Yes")) +
  geom_boxplot() +  
  geom_boxplot(color="black", fill = c(colores_defecto_ggplot[1], colores_defecto_ggplot[2])) +
  ggtitle("Boxplot Survived (by Age")
```

Se ve claramente que las distribuciones son muy parecidas.

#### Age y Embarked

Para analizar si **Age** es independiente del puerto de embarque **Embarked** , podemos realizar un test Anova, donde la hipótesis nula nos dice que la media de la edad es independiente del puerto de embarque, es decir que la media de edad de la gente que subió en “C” (Cherbourg), coincide con la media de los que embarcaron en “Q” (Queenstown) y también con los que embarcaron en “S” (Southampton). Y por el contrario la hipótesis nula es que alguna de las medias es diferente. 

```{r message= FALSE, warning=FALSE}
modelo_anova <- aov(formula = Age ~ Embarked, data =data )
resumen_anova <- summary(modelo_anova)
resumen_anova
```

Observamos dos filas, una que pone “Embarked” y otra que pone “Residuals”. La primera fila corresponde a todo lo relativo a la varianza explicada (la de lavariable independiente “Embarked”) y la segunda fila relativo a la varianza no explicada o residual.

**Explicación de los resultados del test Anova:**

*Df* son los grados de libertad, para el caso de la varianza explicada (la de la variable independiente) es k-1. En nuestro caso como “Embarked” tiene 3 valores posibles, entonces Df=2.

Para la parte de la varianza residual, es n - k, por tanto el valor Df=888 (891 son los registros del dataframe, si le restamos los 2 de antes quedan los 888).

*Sum Sq* es la suma de la diferencia de los cuadrados, conocidos como SCDe (variación entre-grupos) y SCDi (variación intra-grupos). La función nos ha devuelto 427 y 175873 respectivamente.

*Mean Sq* es la media cuadrática referente a entre-grupos e intra-grupos. Lo que también llamamos como Varianza explicada (línea superior, es decir 213.6) y varianza no explicada (línea inferior, es decir 198.1 ). Corresponde al cociente entre la suma de diferencias de cuadrados y los grados de libertad, es decir realmente Mean Sq = Sum Sq / Df lo que se puede comprobar realizando los cálculos sobre los datos anteriores.

*F* Es el estadístico (Fisher-Snedecor), que es el cociente entre la varianza explicada entre la varianza no explicada. Por tanto es el cociente entre los valores Mean Sq, siendo el numerador la fila superior (213.6) y el denominador la fila
inferior (213.6). El valor del cociente es 0.956, es decir el estadístico F.

*Pr(>F)* Es la probabilidad asociada, el p-valor que nos indicará si se rechaza o no la hipotesis nula. En este caso el valor es: 0.442 que es mayor que 0.05 y nos permite aceptar (no rechazar) la hipótesis nula que decía que las medias de la variable “Age” en función del valor de “Embarked” eran iguales.

Revisamos los distintos gráficos que nos proporciona anova

- Gráfico Residuals vs Fitted
```{r message= FALSE, warning=FALSE}
plot(modelo_anova, 1)
```

Esta gráfica nos muestra si los residuos tienen patrones no lineales. Puede existir una relación no lineal entre las variables explicativas y la variable explicada, y ese patrón podría verse en esta gráfica si el modelo no captura esa relación no
lineal. Si los residuos están igualmente distribuidos alrededor de una línea horizontal sin patrones diferentes, es una buena señal de que no hay relaciones no lineales.

En nuestro caso concreto, se ve una línea casi horizontal (hay una mini curva) y los residuos se distribuyen alrededor de dicha línea. Podemos decir que no hay indicios de relaciones no lineales.

- Gráfico Normal Q-Q
```{r message= FALSE, warning=FALSE}
plot(modelo_anova, 2)
```

Si no nos ponemos muy estrictos en la exigencia, con el gráfico Normal Q-Q podemos ver que la variable dependiente sigue una distribución aproximadamente normal. La mayoría de los puntos se encuentran alineados en la línea de puntos y solamente es en los extremos donde esa situación no se cumple.

- Gráfica Scale-Location:

```{r message= FALSE, warning=FALSE}
plot(modelo_anova, 3)
```

La gráfica Scale-Location también es conocida con el nombre de gráfica Spread-Location. Aquí vemos si los residuos se reparten de forma equitativa.En nuestro ejemplo, vemos casi una recta horizontal y los puntos se distribuyen de forma muy similar a los lados de la línea y en los extremos también parece un gráfico simétrico (tanto en horizontal como en vertical). Es decir que el gráfico nos está indicando que se cumple la homocedasticidad en nuestro modelo.

- Gráfica Residuals vs Leverage

```{r message= FALSE, warning=FALSE}
plot(modelo_anova, 5)
```

Esta gráfica sirve para ayudarnos a encontrar casos influyentes (es decir, sujetos) si es que los hay. No todos los valores atípicos son influyentes en el análisis de regresión lineal. En el caso de existir valores extremos (outliers), puede que no sean influyentes para determinar la línea de regresión. Eso significa que los resultados no serían muy diferentes si los incluimos o excluimos del análisis, es decir no son influyentes. Por otra parte, algunos casos podrían ser muy influyentes, incluso aunque parezca que están dentro de un rango razonable de los valores. Pueden ser casos extremos contra una línea de regresión y pueden alterar los resultados si los excluimos del análisis. Es decir, estos no están alineados (tendencia) con la mayoría de los casos.

Tenemos que buscar casos que estén fuera de una línea discontinua (que es la distancia de Cook). Cuando encontremos casos fuera de la distancia de Cook (es decir que tienen puntuación alta de distancia de Cook) se consideran casos influyentes en los resultados de la regresión. Y esa regresión se verá afectada si excluimos esos casos.

- Grafica Distancia de Cook

Otra forma de mostrar la distancia de Cook es usando el gráfico que proporciona Anova

```{r message= FALSE, warning=FALSE}
plot(modelo_anova, 4)
```

Después de este análisis y dando por aceptadas las condiciones del cumplimiento de Anova, podemos afirmar que las medias de edad en los diferentes puertos de Embarke es coincidente.
Y de hecho, si vemos el Boxplot de la variable “Age” en función de la variable “Embarked”:

```{r message= FALSE, warning=FALSE}
ggplot(data, aes(x=Embarked, y=Age)) + 
  geom_boxplot() +
  ggtitle("Boxplot Age (by Embarked")
```

#### Price y Pclass

Intentamos realizar Anova con etas dos variables, usando como hipótesis nula que el precio medio pagado es igual para cada una de las 3 clases

```{r message= FALSE, warning=FALSE}
modelo_anova <- aov(formula = Price ~ Pclass, data =data )
resumen_anova <- summary(modelo_anova)
resumen_anova
```
Si mostramos los gráficos:

```{r message= FALSE, warning=FALSE}
plot(modelo_anova)
```

Observamos que no se cumplen las condicies para aplicar Anova y el test no tienve valor.
Vamos a intentar usar un test no paramétrico, Kruskal Wallis

```{r message= FALSE, warning=FALSE}
modelo_kruskal <- kruskal.test(formula = Price ~ Pclass, data =data )
modelo_kruskal
```

El resultado de este test arroja un p-value inferior a 0.05 y por tanto rechazamos la hipótesis nula.

Lo podemos comprobar también visualmente con el boxplot relativo a ello:

TODO###################Hue_pal
```{r message= FALSE, warning=FALSE}
ggplot(data, aes(x=Pclass, y=Price)) + 
  geom_boxplot() +
  #geom_boxplot(fill = (hue_pal()(3))
  ggtitle("Boxplot Price (by Pclass)")
```

### Modelos

TODO############ explicación mejor de los modelos
Vamos a aplicar diversos modelos

Vamos a utilizar como variables explicativas las variables que traía por defecto el conjunto de datos original (menos las que hemos eliminado en el proceso de transformación y limpieza de datos ya comentado).

Creamos un conjunto de entrenamiento y un conjunto de test. Es decir,vamos a realizar una partición, un 75% de datos para el entrenamiento, y el 25% restante para validar los modelos.

```{r message= FALSE, warning=FALSE}
set.seed(123)

split = sample.split(data$Survived, SplitRatio = 0.75)
data_train = subset(data, split == TRUE)
data_test = subset(data, split == FALSE)

```

#### Modelo de regresión logística

Un modelo de regresión logística es un tipo de análisis de regresión que se utiliza para predecir el resultado de una variable categórica, en función de las variables independientes. En nuestro caso, la variable objetivo “Survived” es una variable categórica binaria, es decir que tomar valor de 0 o 1 (verdadero o falso). La variable toma el valor 1 cuando el pasajero ha sobrevivido al accidente, y 0 en caso contrario.

- Primer modelo glm

Creamos un primer modelo glm1 con las variables "original": **Pclass**, **SibSp**, **Parch**, **Sex**, **Age**, **Fare** y **Embarked**

```{r message= FALSE, warning=FALSE}
modelo_glm1 <- glm(formula=Survived~ Pclass+SibSp+Parch+Sex+Age+Fare+Embarked, data = data_train, family = binomial(link = "logit"))
summary(modelo_glm1)
```

Se puede observar en este modelo que tanto las variables “Fare” como “Parch” no son significativas, es decir, no están aportando nada a la hora de predecir la variable “Survived”.
Además, podemos comprobar el “sentido” de la significación. Por ejemplo, vemos como significativa la variable dummy. Con las variables categóricas se crean automáticamente tantas variables dummy como niveles – 1. En el caso de la variable Sex, al tener 2 valores ha creado la variable “Sexmale”, es decir la parte correspondiente a hombres, mientras que la parte de mujeres forma parte del Intercept del modelo. Concretamente vemos que “Sexmale” es una variable significativa, pero con valor negativo (de las más negativas junto con “Pclass3”). Eso significa que esas variables son una influencia “negativa” de cara a la supervivencia. Es decir, esas variables contribuyen negativamente a la supervivencia, se puede ver por ejemplo que Pclass3 afecta más negativamente que Pclass2.

Ahora usamos el conjunto de datos de test para validar nuestro modelo


TODO#################NO consigo que funcione el predict y el crosttable
```{r message= FALSE, warning=FALSE}
predict_glm1 <- predict.glm(modelo_glm1, data_test, type = 'terms')

```

```{r message= FALSE, warning=FALSE}
#csstab_glm1 <- CrossTable(data_test$Survived, predict_glm1,
#           prop.chisq = FALSE, 
#           proc.c = FALSE, 
#           prop.r = FALSE, 
#           dnn = c('Reality', 'Prediction'))
```

- Segundo modelo glm

Construimos otro modelo (glm2), similar al anterior pero esta vez partiendo de los resultados del modelo anterior, le vamos a quitar aquellas variables que vimos que no eran significativas para el modelo de predicción. Por lo tanto, tendremos un modelo2 cuyas variables a utilizar serán **Pclass**, **SibSp**, **Sex** y **Age**.

```{r message= FALSE, warning=FALSE}
modelo_glm2 <- glm(formula=Survived~ Pclass+SibSp+Sex+Age, data = data_train, family = binomial(link = "logit"))
summary(modelo_glm2)
```

Se comprueba que todas las variables utilizadas son variables significativas para el modelo. Además, el modelo aprece haber mejorado un poco en cuanto a la predicción:

TODO######Código para predict y crosstable



- Tercer modelo glm

Hasta ahora se han utilizado las variables del conjunto de datos “original”. Vamos a construir otro modelo (glm3), pero esta vez vamos a intentar utilizar alguna de las variables que hemos construido para ayudar a predecir la supervivencia. Para este caso vamos a utilizar las variables nuevas **Child** y también **FamilySize**. Además de esas dos variables, vamos a utilizar otras tres variables originales: **Pclass**, **Sex** y **Age**.

```{r message= FALSE, warning=FALSE}
modelo_glm3 <- glm(formula=Survived~ Sex+Pclass+Age+Child+FamilySize,, data = data_train, family = binomial(link = "logit"))
summary(modelo_glm3)
```

Al igual que pasaba en el modelo2, todas las variables utilizadas han resultado significativas, y además el AIC del modelo ha mejorado ligeramente. Además la capacidad predictiva del modelo ha aumentado un poco:

TODO###Código matriz confusion predict y crosstable


- Cuarto modelo glm

Antes de construir un cuarto modelo, vamos a analizar si existen variables independientes que afecten a la variable dependiente.
Para ello primero definimos una variable 'objetivo' pero numérica

```{r message= FALSE, warning=FALSE}
data$SurvivedNum <- as.integer(as.character(data$Survived))
```

Agrupamos el dataset por las variables Sex y Pclass

```{r message= FALSE, warning=FALSE}
data.agrup <- data %>% group_by(Sex, Pclass)
```

Calculamos la media creando un campo 'Mean_survived' de la media

```{r message= FALSE, warning=FALSE}
data.mediasurvived <- summarize(.data = data.agrup, Mean_Survived = mean(SurvivedNum))
kable(data.mediasurvived)
```


```{r message= FALSE, warning=FALSE}
plot1 <- ggplot(data = data.mediasurvived, aes(x=Pclass, y = Mean_Survived, group = Sex)) +
  geom_line(aes(color=Sex), size=1) +
  geom_point(aes(color = Sex, shape=Sex), size=2)+
  theme(legend.position="top") +
  theme(legend.title = element_text(size=12), legend.text = element_text(size=11))
plot2 <- ggplot(data = data.mediasurvived, aes(x=Sex, y = Mean_Survived, group = Pclass)) +
  geom_line(aes(color=Pclass), size=1) +
  geom_point(aes(color = Pclass, shape=Pclass), size=2)+
  theme(legend.position="top") +
  theme(legend.title = element_text(size=12), legend.text = element_text(size=11))
grid.arrange(plot1, plot2, ncol = 2)
  
```

Tanto la variable **Sex** como la variable **Pclass** producen efecto en la variable **Mean_Survived**. También podemos comprobar cómo se produce interacción entre las variables **Sex** y **Pclass** respecto a **Mean_Survived**. Podemos ver cómo hay un descenso muy pronunciado cuando pasamos de mujeres a hombres y estamos tratando la clase 2ª. Observamos además cómo pasar a tercera clase afecta muy negativamente en el caso de las mujeres, ya que aunque no es una línea paralela, el hecho de estar en 1ª o 2ª clase no parece demasiado importante en el caso de las mujeres, pero al pasar a 3ª clase la caída de la media de supervivencia es muy importante.



Agrupamos el dataset por las variables AgeInterval y Sex y realizamos el mismo proceso

```{r message= FALSE, warning=FALSE}
data.agrup <- data %>% group_by(AgeInterval, Sex)

data.mediasurvived <- summarize(.data = data.agrup, Mean_Survived = mean(SurvivedNum))
kable(data.mediasurvived)

plot1 <- ggplot(data = data.mediasurvived, aes(x=Sex, y = Mean_Survived, group = AgeInterval)) +
  geom_line(aes(color=AgeInterval), size=1) +
  geom_point(aes(color = AgeInterval, shape=AgeInterval), size=2)+
  theme(legend.position="top") +
  theme(legend.title = element_text(size=12), legend.text = element_text(size=11))
plot2 <- ggplot(data = data.mediasurvived, aes(x=AgeInterval, y = Mean_Survived, group = Sex)) +
  geom_line(aes(color=Sex), size=1) +
  geom_point(aes(color = Sex, shape=Sex), size=2)+
  theme(legend.position="top") +
  theme(legend.title = element_text(size=12), legend.text = element_text(size=11))
grid.arrange(plot1, plot2, ncol = 2)
  
```

En este caso llama la atención el impacto de cuando pasamos el primer intervalo (menores o iguales
a 12 años) al siguiente intervalo (de 13 a 17 años). La proporción de las mujeres aumenta mientras que en el caso de los hombres disminuye drásticamente. Además, no parece haber apenas diferencia en el primer tramo (los niños, se salvan con independencia del género)


Ahora construimos nuestro cuarto modelo de regresión logística. Utilizaremos algunas variables ya usadas en otros modelos más **AgeInterval**:**Sex**. También hemos añadido la interacción que generan **Sex**:**Pclass**. A estas variables le sumamos también las variables independientes **Sex**, **Parch** y **SibSp**.

```{r message= FALSE, warning=FALSE}
modelo_glm4 <- glm(formula=Survived~Sex+Parch+SibSp+AgeInterval:Sex+Sex:Pclass, data = data_train, family = binomial(link = "logit"))
summary(modelo_glm4)
```
TODO##############Matriz de confusión

##### Resumen modelos regresion

TODO##### Curvas ROC


#### Árboles de decisión

#### Arboles train
TODO

#### Random Forest
TODO


#### C5.0

C5.0 es el algoritmo sucesor de C4.5, publicado por John Ross Quinlan (1992), con el objetivo de crear árboles de clasificación. Entre sus características, destacan la capacidad para generar árboles de decisión simples, modelos basados en reglas, ensembles basados en boosting y asignación de distintos pesos a los errores. Este algoritmo ha resultado de una gran utilidad a la hora de crear modelos de clasificación y todas sus capacidades son accesibles mediante el paquete C50. Aunque comparte muchas características con los algoritmos de random forest y gradient boosting, cabe tener en cuenta algunas peculiaridades:

- La medida de pureza empleada para las divisiones del árbol es la entropía.

- El podado de los árboles se realiza por defecto, y el método empleado se conoce como pessimistic pruning.

- Los árboles se pueden convertir en modelos basados en reglas.

- Emplea un algoritmo de boosting más próximo a AdaBoost que a Gradient Boosting.

- Por defecto, el algoritmo de boosting se detiene si la incorporación de nuevos modelos no aporta un mínimo de mejora.

- Incorpora una estrategia para la selección de predictores (Winnowing) previo ajuste del modelo.

- Permite asignar diferente peso a cada tipo de error.


Creamos primero unas variables para simplificar el uso de los distintos modelos.
- trainX corresponde al dataframe sin la variable Survived (para el conjunto de train)
- trainy es el dataframe pero sólo con la variable Survived (para el conjunto de train)

- testX corresponde al dataframe sin la variable Survived (para el conjunto de test)
- testy es el dataframe pero sólo con la variable Survived (para el conjunto de test)


```{r}
trainX <- data_train[, c(1:3,5:12)]
trainy <- data_train[, 4]
testX <- data_test[, c(1:3,5:12)]
testy <- data_test[, 4]
```

##### Importancia Atributos #####

Vamos a crear una función que nos simplifique la generación de gráficas sobre la importancia de los atributos en un model de árbol C5.0.
Mostraremos dos métricas

- Usage: porcentaje de observaciones de entrenamiento que caen en todos los nodos generados tras una división en el que ha participado el predictor. Por ejemplo, en el caso de un árbol simple, el predictor empleado en la primera decisión recibe automáticamente una importancia del 100%, ya que todas las observaciones de entrenamiento caen en uno de los dos nodos hijos generados. Otros predictores puede que participen con frecuencia en divisiones, pero si en los nodos hijos solo caen unas pocas observaciones, su importancia puede ser próxima a cero. En el caso de boosting, se promedia la importancia de cada predictor en todos los árboles que forman el ensemble.

- Splits: porcentaje de divisiones en las que participa cada predictor. No tiene en cuenta la importancia de la división.




```{r message= FALSE, warning=FALSE}
importancia <- function(fit_tree) {
  imp_usage <- C5imp(fit_tree, metric = "usage")
  imp_usage <- imp_usage %>%
                       rownames_to_column(var = "predictor")
  
  imp_splits <- C5imp(fit_tree, metric = "splits")
  imp_splits <- imp_splits %>%
                       rownames_to_column(var = "predictor")
  
  
  p1 <- ggplot(data = imp_usage, aes(x = reorder(predictor, Overall),
                                             y = Overall, fill = Overall)) +
      labs(x = "", title = "usage") +
      geom_col() +
      coord_flip() +
      scale_fill_viridis_c() +
      theme_bw() +
      theme(legend.position = "none")
  
  p2 <- ggplot(data = imp_splits, aes(x = reorder(predictor, Overall),
                                              y = Overall, fill = Overall)) +
      labs(x = "", title = "splits") +
      geom_col() +
      coord_flip() +
      scale_fill_viridis_c() +
      theme_bw() +
      theme(legend.position = "none")
  ggarrange(p1, p2)
}
```


##### Primer modelo c5.0

Vamos a empezar realizando un primer modelo C5.0 con los valores por defecto y con las reglas:


```{r}
bc_tree <- C5.0(trainX, trainy, rules=TRUE )
summary(bc_tree)
```
Errors muestra el número y porcentaje de casos mal clasificados en el subconjunto de entrenamiento. El árbol obtenido clasifica erróneamente 79 668 casos dados, una tasa de error del 11.8%.

Aunque podríamos representar el árbol, nos han salido 21 reglas y es complicado de visualizar. Lo analizamos númericamente.

Primero veamos visualmente la importancia de cada variable:


```{r}
importancia(bc_tree)
```
Está usando todas las variables, de ahí que nos salgan tantas reglas.

Vamos a ver la precisión del modelo

```{r message= FALSE, warning=FALSE}
predicted_model <- predict( model, testX, type="class" )
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == testy) / length(predicted_model)))
```
Y su matriz de confusión:

```{r message= FALSE, warning=FALSE}
mat_conf<-table(testy,Predicted=predicted_model)
mat_conf
```
Se observa que tenemos 35 errores de clasificación.

##### Segundo modelo C5.0 con Winnowing

Winnowing consiste en aplicar un algoritmo de clasificación (algoritmo Winnow) a los atributos para eliminar aquellos que sean de poca ayuda.

Es una selección de atributos que se realiza antes de la creación del modelo.

El conjunto de datos se divide por la mitad aleatoriamente y se crea un modelo inicial. Cada predictor se va quitando por turno y se analiza el efecto sobre la calidad del modelo (usando la otra mitad de la división aleatoria)

Se marcan los predictores si su eliminación no incrementa la tasa de error. El modelo final se calcula usando todos los conjuntos de datos usando sólo los predictores no marcados.

Se puede realizar winnowing en C5.0 simplemente usando un flag.

```{r message= FALSE, warning=FALSE}
bc_winno_tree <- C5.0(
                      formula = Survived ~ ., 
                      data    = data_train,
                      rules   = TRUE,
                      control = C5.0Control(seed = 123, winnow = TRUE)
                    )
summary(bc_winno_tree)
```
Tenemos bastantes menos reglas que antes.

Vamos a ver cuantas variables ha utilizado ahora:

```{r message= FALSE, warning=FALSE}
importancia(bc_winno_tree)
```
Hay dos atributos que directamente no son usados, comprobamos si hemos mejorado la calidad del modelo. Usamos la matriz de confusión

```{r message= FALSE, warning=FALSE}
bc_winno_tree_pred <- predict( bc_winno_tree, testX, type="class" )
```

```{r message= FALSE, warning=FALSE}
mat_conf<-table(testy, Predicted=bc_winno_tree_pred)
mat_conf
```
Tenemos 30 errores en este caso.

```{r message= FALSE, warning=FALSE}

porcentaje_correct<-100 * sum(diag(mat_conf)) / sum(mat_conf)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",porcentaje_correct))

```

Hemos mejorado casi dos puntos, obteniendo el mejor modelo por el momento


##### Tercer modelo C5.0 usando boosting

La implementación del C5.0 dispone de la posibilidad de aplicar un *Boosting* similar a *AdaBoost*, que permite combinar varios árboles (técnica de *Ensemble*) para producir mejores modelos predictivos que si sólamente usasemos un árbol de decisión simple.

Para ello se utiliza el parámetro ```trials```, en el que le indicamos cuantas iteraciones (que a la postre son árboles distintos) debe utilizar para generar el modelo *ensemble*.

Podríamos ir probando con distintos boosts variando el winnowing y los parámetros hasta encontrar el que mejor modelo nos generase.
Es una labor tediosa que podemos simplificar usando la librería ```caret```, que proporciona una forma de entrenar modelos modificando sus parámetros, vamos a usarlo para el C5.0  mostrando la comparativa posteriormente.

En este caso vamos a usar Cohen-Kappa como medición de calidad del modelo, y compararemos C5.0 generados con distintas iteraciones (boosting) combinándolo con winnowing y con rules/tree.


```{r message= FALSE, warning=FALSE}

tuned <- train(trainX, trainy, method = "C5.0", tuneLength = 11,
 trControl = trainControl(method = "repeatedcv",
 repeats = 5),
 metric = "Kappa")
```

```{r message= FALSE, warning=FALSE}
postResample(predict(tuned, testX), testy)
plot(tuned, metric = "Kappa")
```

Los valores anteriores son orientativos y nos sirven para acotar más facilmente los parámetros en los que buscar.

Vamos a crear el mejor árbol con winnowing y boost, usando 50 trials y sin reglas:

```{r message= FALSE, warning=FALSE}
bc_boost_tree <- C5.0(
                      formula = Survived ~ ., 
                      data    = data_train,
                      rules   = FALSE,
                      control = C5.0Control(seed = 123, winnow = TRUE),
                      trials = 50
                    )
```


Como antes, vemos la importancia de los atributos:

```{r message= FALSE, warning=FALSE}
importancia(bc_boost_tree)
```
Em este caso todos los atributos tienen un uso muy alto.

De nuevo calculamos matriz de confusión

```{r message= FALSE, warning=FALSE}
bc_boost_tree_pred <- predict( bc_boost_tree, testX, type="class" )
mat_conf<-table(testy, Predicted=bc_boost_tree_pred)
mat_conf
```
Tenemos 27 errores en este caso.

```{r message= FALSE, warning=FALSE}

porcentaje_correct<-100 * sum(diag(mat_conf)) / sum(mat_conf)
print(sprintf("El %% de registros correctamente clasificados es: %.4f %%",porcentaje_correct))

```
Hemos conseguido mejorar en casi un punto porcentual.

\newpage
# Representación de los resultados a partir de tablas y gráficas.
TODO
¿Ponemos algo explicando que se han ido mostrando a lo largo de los distintos puntos o simplemente lo quitamos?

# Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

Hemos procedido a realizar, sobre el conjunto de datos Titanic, las fases de limpieza, depuración y análisis de datos (eliminando variables innecesarias,
imputando datos faltantes, comprobando supuestos estadísticos...), hasta finalmente implementar un conjunto de modelos de predicción basados en variables
dadas y otras creadas nuevas.

El problema que nos planteábamos era: ¿Dado el conjunto de datos que disponemos, podemos predecir la supervivencia o no de un pasajero?
Los diferentes modelos creados intentan resolverlo con resultados de precisión más bien discretos.

Los modelos que mejor han funcionado han sido los árboles de decisión C5.0, y sobre todo el tercer árbol con boosting de 50 y winnowing con casi un 88% de precisión. No obstante utiliza todos los atributos y no es fácil de visualizar.

Del resto de modelos planteado destacaríamos tres de ellos con precisión de 83,78%: Dos regresiones
logísticas usando datos enriquecidos con variables sintéticas, y un árbol de decisión con profundidad 5 para el que las variables más significativas resultaron ser
las siguientes: **Sexmale**, **Pclass3** y **FamilySize** (aunque también hemos visto que hay otras variables influyentes en los modelos, y que eran de esperar
como **Age** y sus variables derivadas, como **Child** y **AgeInterval** y que suponen también una lógica). 

También hemos comprobado que la regresión logística con interacción de variables (modelo glm4) mejora la predicción de supervivientes (a costa de fallar algo más en los no supervivientes).
Aunque la precisión total de ambos modelos fue equivalente, en el modelo de regresión logística ha fallado en que fallecen el 11,68% y el modelo predice que sobreviven (y sobreviven el 23.53% y el modelo predice lo contrario),
mientras que en el árbol (tree2) se ha fallado en lo siguiente, fallecen realmente un 7,30% y el modelo predice que sobreviven (y sobreviven el 30,59% y el modelo predice que mueren). 

Creemos que es preferible que se equivoque más en la predicción de que no van a sobrevivir y al final si lo hacen que en lo contrario (que se prediga que sobrevive y luego no lo haga)
Esto parece tener sentido, ya que si observamos las 2 variables más importantes del árbol, Sexmale (hombres) y Pclass3 (3a clase), precisamente son las variables que suponen el mayor índice de mortalidad.


## Exportación de los datos

Vamos a exportar dos ficheros que estarán disponibles en el repositorio github:
- Un fichero “titanic_final.csv” que contiene las 12 variables con las que se ha trabajado, con la imputación de los datos realizada, con las variables no utilizadas del dataset origen eliminadas, y con las transformaciones
que hemos considerado necesarias.

- Un fichero “titanic_predict.csv”, en el que además de las columnas que tiene el fichero anterior, tiene una columna nueva llamada “Survived_Predicted”, que es la columna con la predicción de la variable “Survived” realizada con el modelo escogido.

TODO##### Exportación de los datos
```{r}

```


# Tabla de contribuciones

| Contribuciones              | Firma                                    | 
|-----------------------------|------------------------------------------|
| Investigación Previa        | Alexis Germán Arroyo Peña, Gabriel Pulido de Torres  |
| Redacción de las respuestas | Alexis Germán Arroyo Peña, Gabriel Pulido de Torres  |
| Desarrollo código           | Alexis Germán Arroyo Peña, Gabriel Pulido de Torres |

# Bibliografía y referencias
